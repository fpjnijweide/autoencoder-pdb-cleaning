{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated experiments\n",
    "\n",
    "This file contains an extended version of the code shown in continuous_variable_training.ipynb. Several options are added, such as convolutional layers, Gaussian kernels, and the ability to use a variational autoencoder. Methods were written so that a queue of experiments can be made, while the amount of outputs is heavily reduced.\n",
    "\n",
    "After running the experiments, the data was copied into a text editor, and using regular expressions, lines that do not contain curly brackets (such lines only contain information which is useful to see training progress) were removed. This data can be pasted into a program such as Google Sheets or Microsoft Excel, and split into multiple columns (like in a .csv file) using the semicolon as delimiter. The result of this can be seen in the .xlsx file included in this folder.\n",
    "\n",
    "For detailed explanations on the code, please look at continuous_variable_training.ipynb\n",
    "\n",
    "PS. these experiments will take several days to run on modern desktop computers. You might want to comment some of the lines in the second code cell to reduce the amount of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Imports done\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# import sys\n",
    "# class PseudoTTY(object):\n",
    "#     def __init__(self, underlying):\n",
    "#         self.__underlying = underlying\n",
    "#     def __getattr__(self, name):\n",
    "#         return getattr(self.__underlying, name)\n",
    "#     def isatty(self):\n",
    "#         return True\n",
    "\n",
    "# sys.stdout = PseudoTTY(sys.stdout)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import ipykernel\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "# from PIL import Image\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import sklearn.model_selection\n",
    "import os\n",
    "import neural_structured_learning as nsl\n",
    "import math\n",
    "import gc\n",
    "import gkernel #gkernel.py in this folder\n",
    "# import gkernel\n",
    "# import functools\n",
    "import dill\n",
    "from tensorflow.python.util import dispatch\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# oldprint=print    \n",
    "\n",
    "\n",
    "# def newprint(x):\n",
    "#     if isinstance(x,str):\n",
    "#         oldprint(x)\n",
    "#     else:\n",
    "#         display(x)\n",
    "        \n",
    "# print=newprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Imports done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 9085416462515404410\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 2936999463813479726\nphysical_device_desc: \"device: XLA_CPU device\"\n]\n2.3.0\nNum GPUs Available: 0\nWARNING:tensorflow:From <ipython-input-2-c85ea95ca0ce>:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \" + str(len(tf.config.experimental.list_physical_devices('GPU'))))\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN_EPOCHS = False\n",
    "TEST_RUN_EPOCH_NR = 1\n",
    "LOAD_DATA = True\n",
    "verbosity = 0\n",
    "\n",
    "# # Default Variables for experiments.You probably want to use the cell above to change experiment vars.\n",
    "BN_size_default =3 # amount of BN variables, minimum 3\n",
    "\n",
    "mu_default  =0\n",
    "sigma_default = lambda SD: 0.01 # Distribution of the noise\n",
    "gaussian_noise_sigma_default = lambda SD: 0.05\n",
    "sampling_density_default =4 # How many bins the quasi-continuous variables use for distributing their probabilities. Higher_default = better approximation of continuous distributions\n",
    "\n",
    "activation_types_default = [keras.backend.sin,keras.backend.cos,keras.activations.linear, 'relu', 'swish'] # Activation layer types\n",
    "hidden_layers_default =3 # amount of hidden layers\n",
    "encoding_dim_default = BN_size_default # The dimensionality of the middle layer\n",
    "loss_function_default = keras.losses.categorical_crossentropy\n",
    "training_method_default ='semi'\n",
    "activity_regularizer_default=None\n",
    "input_layer_type_default='gaussian_noise'\n",
    "labeled_data_percentage_default=2\n",
    "\n",
    "epochs_default=100\n",
    "VAE_default = False\n",
    "CNN_default = False\n",
    "kernel_landmarks_default = 100\n",
    "\n",
    "CNN_layers_default = 1\n",
    "CNN_filters_default = 64\n",
    "CNN_kernel_size_default = 3\n",
    "\n",
    "use_gaussian_noise_default=True\n",
    "use_missing_entry_default=False\n",
    "missing_entry_prob_default=0.01\n",
    "\n",
    "defaults={}\n",
    "defaults['BN_size']=BN_size_default\n",
    "\n",
    "defaults['mu']=mu_default\n",
    "defaults['sigma']=sigma_default\n",
    "defaults['sampling_density']=sampling_density_default\n",
    "defaults['gaussian_noise_sigma']=gaussian_noise_sigma_default\n",
    "defaults['activation_types']=activation_types_default\n",
    "defaults['hidden_layers']=hidden_layers_default\n",
    "defaults['encoding_dim']=encoding_dim_default\n",
    "defaults['loss_function']=loss_function_default\n",
    "defaults['training_method']=training_method_default\n",
    "defaults['activity_regularizer']=activity_regularizer_default\n",
    "defaults['input_layer_type']=input_layer_type_default\n",
    "defaults['labeled_data_percentage']=labeled_data_percentage_default\n",
    "\n",
    "defaults['epochs']=epochs_default\n",
    "defaults['VAE']=VAE_default\n",
    "defaults['CNN']=CNN_default\n",
    "defaults['kernel_landmarks']=kernel_landmarks_default\n",
    "\n",
    "defaults['CNN_layers']=CNN_layers_default\n",
    "defaults['CNN_filters']=CNN_filters_default\n",
    "defaults['CNN_kernel_size']=CNN_kernel_size_default\n",
    "\n",
    "defaults['use_gaussian_noise'] = use_gaussian_noise_default\n",
    "defaults['use_missing_entry'] = use_missing_entry_default\n",
    "defaults['missing_entry_prob'] = missing_entry_prob_default\n",
    "\n",
    "parameters=list(defaults.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "E, SD=4    missing_entry    0.05\n",
      "CCE, SD=4    missing_entry    0.1\n",
      "CCE, SD=4    missing_entry    0.5\n",
      "CCE, SD=4    missing_entry_combined    0.001\n",
      "CCE, SD=4    missing_entry_combined    0.005\n",
      "CCE, SD=4    missing_entry_combined    0.01\n",
      "CCE, SD=4    missing_entry_combined    0.05\n",
      "CCE, SD=4    missing_entry_combined    0.1\n",
      "CCE, SD=4    missing_entry_combined    0.5\n",
      "JSD, SD=4    training_method    supervised\n",
      "JSD, SD=4    training_method    supervised_2_percent\n",
      "JSD, SD=4    training_method    semi\n",
      "JSD, SD=4    training_method    semi_sup_first\n",
      "JSD, SD=4    training_method    semi_mixed\n",
      "JSD, SD=4    training_method    unsupervised\n",
      "JSD, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "JSD, SD=4    activation_types    ['relu']\n",
      "JSD, SD=4    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "JSD, SD=4    activation_types    ['sin', 'cos', 'linear']\n",
      "JSD, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "JSD, SD=4    input_layer_type    dense\n",
      "JSD, SD=4    input_layer_type    gaussian_noise\n",
      "JSD, SD=4    input_layer_type    gaussian_dropout\n",
      "JSD, SD=4    input_layer_type    sqrt_softmax\n",
      "JSD, SD=4    input_layer_type    gaussian_kernel\n",
      "JSD, SD=4    input_layer_type    CNN\n",
      "JSD, SD=4    input_layer_type    VAE\n",
      "JSD, SD=4    encoding_dim    2\n",
      "JSD, SD=4    encoding_dim    3\n",
      "JSD, SD=4    encoding_dim    6\n",
      "JSD, SD=4    hidden_layers    3\n",
      "JSD, SD=4    hidden_layers    5\n",
      "JSD, SD=4    hidden_layers    7\n",
      "JSD, SD=4    hidden_layers    9\n",
      "JSD, SD=4    hidden_layers    27\n",
      "JSD, SD=4    activity_regularizer    \n",
      "JSD, SD=4    activity_regularizer    L2: 0.01\n",
      "JSD, SD=4    activity_regularizer    L2: 10^-4\n",
      "JSD, SD=4    activity_regularizer    L1: 0.01\n",
      "JSD, SD=4    activity_regularizer    L1: 10^-4\n",
      "JSD, SD=4    sigma    0.01/SD\n",
      "JSD, SD=4    sigma    (0.01*4)/SD\n",
      "JSD, SD=4    sigma    0.01/math.sqrt(SD)\n",
      "JSD, SD=4    sigma    0.01\n",
      "JSD, SD=4    sigma    0.05\n",
      "JSD, SD=4    sigma    0.1\n",
      "JSD, SD=4    sigma    0.2\n",
      "JSD, SD=4    BN_size    2\n",
      "JSD, SD=4    BN_size    3\n",
      "JSD, SD=4    BN_size    4\n",
      "JSD, SD=4    BN_size    5\n",
      "JSD, SD=4    BN_size    10\n",
      "JSD, SD=4    BN_size    20\n",
      "JSD, SD=4    BN_size    30\n",
      "JSD, SD=4    labeled_data_percentage    99\n",
      "JSD, SD=4    labeled_data_percentage    50\n",
      "JSD, SD=4    labeled_data_percentage    20\n",
      "JSD, SD=4    labeled_data_percentage    10\n",
      "JSD, SD=4    labeled_data_percentage    5\n",
      "JSD, SD=4    labeled_data_percentage    2\n",
      "JSD, SD=4    labeled_data_percentage    1\n",
      "JSD, SD=4    labeled_data_percentage    0.5\n",
      "JSD, SD=4    labeled_data_percentage    0.25\n",
      "JSD, SD=4    labeled_data_percentage    0.125\n",
      "JSD, SD=4    labeled_data_percentage    0.05\n",
      "JSD, SD=4    labeled_data_percentage    0.01\n",
      "JSD, SD=4    sampling_density    4\n",
      "JSD, SD=4    sampling_density    15\n",
      "JSD, SD=4    sampling_density    25\n",
      "JSD, SD=4    sampling_density    50\n",
      "JSD, SD=4    sampling_density    100\n",
      "JSD, SD=4    sampling_density    150\n",
      "JSD, SD=4    sampling_density    300\n",
      "JSD, SD=4    gaussian_noise_sigma    0.01/SD\n",
      "JSD, SD=4    gaussian_noise_sigma    (0.01*4)/SD\n",
      "JSD, SD=4    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "JSD, SD=4    gaussian_noise_sigma    0.01\n",
      "JSD, SD=4    gaussian_noise_sigma    0.05\n",
      "JSD, SD=4    gaussian_noise_sigma    0.1\n",
      "JSD, SD=4    gaussian_noise_sigma    0.2\n",
      "JSD, SD=4    missing_entry    0.001\n",
      "JSD, SD=4    missing_entry    0.005\n",
      "JSD, SD=4    missing_entry    0.01\n",
      "JSD, SD=4    missing_entry    0.05\n",
      "JSD, SD=4    missing_entry    0.1\n",
      "JSD, SD=4    missing_entry    0.5\n",
      "JSD, SD=4    missing_entry_combined    0.001\n",
      "JSD, SD=4    missing_entry_combined    0.005\n",
      "JSD, SD=4    missing_entry_combined    0.01\n",
      "JSD, SD=4    missing_entry_combined    0.05\n",
      "JSD, SD=4    missing_entry_combined    0.1\n",
      "JSD, SD=4    missing_entry_combined    0.5\n",
      "CCEu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "CCEu, SD=4    activation_types    ['relu']\n",
      "CCEu, SD=4    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "CCEu, SD=4    activation_types    ['sin', 'cos', 'linear']\n",
      "CCEu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "CCEu, SD=4    input_layer_type    dense\n",
      "CCEu, SD=4    input_layer_type    gaussian_noise\n",
      "CCEu, SD=4    input_layer_type    gaussian_dropout\n",
      "CCEu, SD=4    input_layer_type    sqrt_softmax\n",
      "CCEu, SD=4    input_layer_type    gaussian_kernel\n",
      "CCEu, SD=4    input_layer_type    CNN\n",
      "CCEu, SD=4    input_layer_type    VAE\n",
      "CCEu, SD=4    encoding_dim    2\n",
      "CCEu, SD=4    encoding_dim    3\n",
      "CCEu, SD=4    encoding_dim    6\n",
      "CCEu, SD=4    hidden_layers    3\n",
      "CCEu, SD=4    hidden_layers    5\n",
      "CCEu, SD=4    hidden_layers    7\n",
      "CCEu, SD=4    hidden_layers    9\n",
      "CCEu, SD=4    hidden_layers    27\n",
      "CCEu, SD=4    activity_regularizer    \n",
      "CCEu, SD=4    activity_regularizer    L2: 0.01\n",
      "CCEu, SD=4    activity_regularizer    L2: 10^-4\n",
      "CCEu, SD=4    activity_regularizer    L1: 0.01\n",
      "CCEu, SD=4    activity_regularizer    L1: 10^-4\n",
      "CCEu, SD=4    sigma    0.01/SD\n",
      "CCEu, SD=4    sigma    (0.01*4)/SD\n",
      "CCEu, SD=4    sigma    0.01/math.sqrt(SD)\n",
      "CCEu, SD=4    sigma    0.01\n",
      "CCEu, SD=4    sigma    0.05\n",
      "CCEu, SD=4    sigma    0.1\n",
      "CCEu, SD=4    sigma    0.2\n",
      "CCEu, SD=4    BN_size    2\n",
      "CCEu, SD=4    BN_size    3\n",
      "CCEu, SD=4    BN_size    4\n",
      "CCEu, SD=4    BN_size    5\n",
      "CCEu, SD=4    BN_size    10\n",
      "CCEu, SD=4    BN_size    20\n",
      "CCEu, SD=4    BN_size    30\n",
      "CCEu, SD=4    sampling_density    4\n",
      "CCEu, SD=4    sampling_density    15\n",
      "CCEu, SD=4    sampling_density    25\n",
      "CCEu, SD=4    sampling_density    50\n",
      "CCEu, SD=4    sampling_density    100\n",
      "CCEu, SD=4    sampling_density    150\n",
      "CCEu, SD=4    sampling_density    300\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.01/SD\n",
      "CCEu, SD=4    gaussian_noise_sigma    (0.01*4)/SD\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.01\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.05\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.1\n",
      "CCEu, SD=4    gaussian_noise_sigma    0.2\n",
      "CCEu, SD=4    missing_entry    0.001\n",
      "CCEu, SD=4    missing_entry    0.005\n",
      "CCEu, SD=4    missing_entry    0.01\n",
      "CCEu, SD=4    missing_entry    0.05\n",
      "CCEu, SD=4    missing_entry    0.1\n",
      "CCEu, SD=4    missing_entry    0.5\n",
      "CCEu, SD=4    missing_entry_combined    0.001\n",
      "CCEu, SD=4    missing_entry_combined    0.005\n",
      "CCEu, SD=4    missing_entry_combined    0.01\n",
      "CCEu, SD=4    missing_entry_combined    0.05\n",
      "CCEu, SD=4    missing_entry_combined    0.1\n",
      "CCEu, SD=4    missing_entry_combined    0.5\n",
      "JSDu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "JSDu, SD=4    activation_types    ['relu']\n",
      "JSDu, SD=4    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "JSDu, SD=4    activation_types    ['sin', 'cos', 'linear']\n",
      "JSDu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "JSDu, SD=4    input_layer_type    dense\n",
      "JSDu, SD=4    input_layer_type    gaussian_noise\n",
      "JSDu, SD=4    input_layer_type    gaussian_dropout\n",
      "JSDu, SD=4    input_layer_type    sqrt_softmax\n",
      "JSDu, SD=4    input_layer_type    gaussian_kernel\n",
      "JSDu, SD=4    input_layer_type    CNN\n",
      "JSDu, SD=4    input_layer_type    VAE\n",
      "JSDu, SD=4    encoding_dim    2\n",
      "JSDu, SD=4    encoding_dim    3\n",
      "JSDu, SD=4    encoding_dim    6\n",
      "JSDu, SD=4    hidden_layers    3\n",
      "JSDu, SD=4    hidden_layers    5\n",
      "JSDu, SD=4    hidden_layers    7\n",
      "JSDu, SD=4    hidden_layers    9\n",
      "JSDu, SD=4    hidden_layers    27\n",
      "JSDu, SD=4    activity_regularizer    \n",
      "JSDu, SD=4    activity_regularizer    L2: 0.01\n",
      "JSDu, SD=4    activity_regularizer    L2: 10^-4\n",
      "JSDu, SD=4    activity_regularizer    L1: 0.01\n",
      "JSDu, SD=4    activity_regularizer    L1: 10^-4\n",
      "JSDu, SD=4    sigma    0.01/SD\n",
      "JSDu, SD=4    sigma    (0.01*4)/SD\n",
      "JSDu, SD=4    sigma    0.01/math.sqrt(SD)\n",
      "JSDu, SD=4    sigma    0.01\n",
      "JSDu, SD=4    sigma    0.05\n",
      "JSDu, SD=4    sigma    0.1\n",
      "JSDu, SD=4    sigma    0.2\n",
      "JSDu, SD=4    BN_size    2\n",
      "JSDu, SD=4    BN_size    3\n",
      "JSDu, SD=4    BN_size    4\n",
      "JSDu, SD=4    BN_size    5\n",
      "JSDu, SD=4    BN_size    10\n",
      "JSDu, SD=4    BN_size    20\n",
      "JSDu, SD=4    BN_size    30\n",
      "JSDu, SD=4    sampling_density    4\n",
      "JSDu, SD=4    sampling_density    15\n",
      "JSDu, SD=4    sampling_density    25\n",
      "JSDu, SD=4    sampling_density    50\n",
      "JSDu, SD=4    sampling_density    100\n",
      "JSDu, SD=4    sampling_density    150\n",
      "JSDu, SD=4    sampling_density    300\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.01/SD\n",
      "JSDu, SD=4    gaussian_noise_sigma    (0.01*4)/SD\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.01\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.05\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.1\n",
      "JSDu, SD=4    gaussian_noise_sigma    0.2\n",
      "JSDu, SD=4    missing_entry    0.001\n",
      "JSDu, SD=4    missing_entry    0.005\n",
      "JSDu, SD=4    missing_entry    0.01\n",
      "JSDu, SD=4    missing_entry    0.05\n",
      "JSDu, SD=4    missing_entry    0.1\n",
      "JSDu, SD=4    missing_entry    0.5\n",
      "JSDu, SD=4    missing_entry_combined    0.001\n",
      "JSDu, SD=4    missing_entry_combined    0.005\n",
      "JSDu, SD=4    missing_entry_combined    0.01\n",
      "JSDu, SD=4    missing_entry_combined    0.05\n",
      "JSDu, SD=4    missing_entry_combined    0.1\n",
      "JSDu, SD=4    missing_entry_combined    0.5\n",
      "CCE, SD=100    training_method    supervised\n",
      "CCE, SD=100    training_method    supervised_2_percent\n",
      "CCE, SD=100    training_method    semi\n",
      "CCE, SD=100    training_method    semi_sup_first\n",
      "CCE, SD=100    training_method    semi_mixed\n",
      "CCE, SD=100    training_method    unsupervised\n",
      "CCE, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "CCE, SD=100    activation_types    ['relu']\n",
      "CCE, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "CCE, SD=100    activation_types    ['sin', 'cos', 'linear']\n",
      "CCE, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "CCE, SD=100    input_layer_type    dense\n",
      "CCE, SD=100    input_layer_type    gaussian_noise\n",
      "CCE, SD=100    input_layer_type    gaussian_dropout\n",
      "CCE, SD=100    input_layer_type    sqrt_softmax\n",
      "CCE, SD=100    input_layer_type    gaussian_kernel\n",
      "CCE, SD=100    input_layer_type    CNN\n",
      "CCE, SD=100    input_layer_type    VAE\n",
      "CCE, SD=100    encoding_dim    2\n",
      "CCE, SD=100    encoding_dim    3\n",
      "CCE, SD=100    encoding_dim    6\n",
      "CCE, SD=100    hidden_layers    3\n",
      "CCE, SD=100    hidden_layers    5\n",
      "CCE, SD=100    hidden_layers    7\n",
      "CCE, SD=100    hidden_layers    9\n",
      "CCE, SD=100    hidden_layers    27\n",
      "CCE, SD=100    activity_regularizer    \n",
      "CCE, SD=100    activity_regularizer    L2: 0.01\n",
      "CCE, SD=100    activity_regularizer    L2: 10^-4\n",
      "CCE, SD=100    activity_regularizer    L1: 0.01\n",
      "CCE, SD=100    activity_regularizer    L1: 10^-4\n",
      "CCE, SD=100    sigma    0.01/SD\n",
      "CCE, SD=100    sigma    (0.01*4)/SD\n",
      "CCE, SD=100    sigma    0.01/math.sqrt(SD)\n",
      "CCE, SD=100    sigma    0.01\n",
      "CCE, SD=100    sigma    0.05\n",
      "CCE, SD=100    sigma    0.1\n",
      "CCE, SD=100    sigma    0.2\n",
      "CCE, SD=100    BN_size    2\n",
      "CCE, SD=100    BN_size    3\n",
      "CCE, SD=100    BN_size    4\n",
      "CCE, SD=100    BN_size    5\n",
      "CCE, SD=100    labeled_data_percentage    99\n",
      "CCE, SD=100    labeled_data_percentage    50\n",
      "CCE, SD=100    labeled_data_percentage    20\n",
      "CCE, SD=100    labeled_data_percentage    10\n",
      "CCE, SD=100    labeled_data_percentage    5\n",
      "CCE, SD=100    labeled_data_percentage    2\n",
      "CCE, SD=100    labeled_data_percentage    1\n",
      "CCE, SD=100    labeled_data_percentage    0.5\n",
      "CCE, SD=100    labeled_data_percentage    0.25\n",
      "CCE, SD=100    labeled_data_percentage    0.125\n",
      "CCE, SD=100    labeled_data_percentage    0.05\n",
      "CCE, SD=100    labeled_data_percentage    0.01\n",
      "CCE, SD=100    gaussian_noise_sigma    0.01/SD\n",
      "CCE, SD=100    gaussian_noise_sigma    (0.01*4)/SD\n",
      "CCE, SD=100    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "CCE, SD=100    gaussian_noise_sigma    0.01\n",
      "CCE, SD=100    gaussian_noise_sigma    0.05\n",
      "CCE, SD=100    gaussian_noise_sigma    0.1\n",
      "CCE, SD=100    gaussian_noise_sigma    0.2\n",
      "CCE, SD=100    missing_entry    0.001\n",
      "CCE, SD=100    missing_entry    0.005\n",
      "CCE, SD=100    missing_entry    0.01\n",
      "CCE, SD=100    missing_entry    0.05\n",
      "CCE, SD=100    missing_entry    0.1\n",
      "CCE, SD=100    missing_entry    0.5\n",
      "CCE, SD=100    missing_entry_combined    0.001\n",
      "CCE, SD=100    missing_entry_combined    0.005\n",
      "CCE, SD=100    missing_entry_combined    0.01\n",
      "CCE, SD=100    missing_entry_combined    0.05\n",
      "CCE, SD=100    missing_entry_combined    0.1\n",
      "CCE, SD=100    missing_entry_combined    0.5\n",
      "JSD, SD=100    training_method    supervised\n",
      "JSD, SD=100    training_method    supervised_2_percent\n",
      "JSD, SD=100    training_method    semi\n",
      "JSD, SD=100    training_method    semi_sup_first\n",
      "JSD, SD=100    training_method    semi_mixed\n",
      "JSD, SD=100    training_method    unsupervised\n",
      "JSD, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "JSD, SD=100    activation_types    ['relu']\n",
      "JSD, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "JSD, SD=100    activation_types    ['sin', 'cos', 'linear']\n",
      "JSD, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "JSD, SD=100    input_layer_type    dense\n",
      "JSD, SD=100    input_layer_type    gaussian_noise\n",
      "JSD, SD=100    input_layer_type    gaussian_dropout\n",
      "JSD, SD=100    input_layer_type    sqrt_softmax\n",
      "JSD, SD=100    input_layer_type    gaussian_kernel\n",
      "JSD, SD=100    input_layer_type    CNN\n",
      "JSD, SD=100    input_layer_type    VAE\n",
      "JSD, SD=100    encoding_dim    2\n",
      "JSD, SD=100    encoding_dim    3\n",
      "JSD, SD=100    encoding_dim    6\n",
      "JSD, SD=100    hidden_layers    3\n",
      "JSD, SD=100    hidden_layers    5\n",
      "JSD, SD=100    hidden_layers    7\n",
      "JSD, SD=100    hidden_layers    9\n",
      "JSD, SD=100    hidden_layers    27\n",
      "JSD, SD=100    activity_regularizer    \n",
      "JSD, SD=100    activity_regularizer    L2: 0.01\n",
      "JSD, SD=100    activity_regularizer    L2: 10^-4\n",
      "JSD, SD=100    activity_regularizer    L1: 0.01\n",
      "JSD, SD=100    activity_regularizer    L1: 10^-4\n",
      "JSD, SD=100    sigma    0.01/SD\n",
      "JSD, SD=100    sigma    (0.01*4)/SD\n",
      "JSD, SD=100    sigma    0.01/math.sqrt(SD)\n",
      "JSD, SD=100    sigma    0.01\n",
      "JSD, SD=100    sigma    0.05\n",
      "JSD, SD=100    sigma    0.1\n",
      "JSD, SD=100    sigma    0.2\n",
      "JSD, SD=100    BN_size    2\n",
      "JSD, SD=100    BN_size    3\n",
      "JSD, SD=100    BN_size    4\n",
      "JSD, SD=100    BN_size    5\n",
      "JSD, SD=100    labeled_data_percentage    99\n",
      "JSD, SD=100    labeled_data_percentage    50\n",
      "JSD, SD=100    labeled_data_percentage    20\n",
      "JSD, SD=100    labeled_data_percentage    10\n",
      "JSD, SD=100    labeled_data_percentage    5\n",
      "JSD, SD=100    labeled_data_percentage    2\n",
      "JSD, SD=100    labeled_data_percentage    1\n",
      "JSD, SD=100    labeled_data_percentage    0.5\n",
      "JSD, SD=100    labeled_data_percentage    0.25\n",
      "JSD, SD=100    labeled_data_percentage    0.125\n",
      "JSD, SD=100    labeled_data_percentage    0.05\n",
      "JSD, SD=100    labeled_data_percentage    0.01\n",
      "JSD, SD=100    gaussian_noise_sigma    0.01/SD\n",
      "JSD, SD=100    gaussian_noise_sigma    (0.01*4)/SD\n",
      "JSD, SD=100    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "JSD, SD=100    gaussian_noise_sigma    0.01\n",
      "JSD, SD=100    gaussian_noise_sigma    0.05\n",
      "JSD, SD=100    gaussian_noise_sigma    0.1\n",
      "JSD, SD=100    gaussian_noise_sigma    0.2\n",
      "JSD, SD=100    missing_entry    0.001\n",
      "JSD, SD=100    missing_entry    0.005\n",
      "JSD, SD=100    missing_entry    0.01\n",
      "JSD, SD=100    missing_entry    0.05\n",
      "JSD, SD=100    missing_entry    0.1\n",
      "JSD, SD=100    missing_entry    0.5\n",
      "JSD, SD=100    missing_entry_combined    0.001\n",
      "JSD, SD=100    missing_entry_combined    0.005\n",
      "JSD, SD=100    missing_entry_combined    0.01\n",
      "JSD, SD=100    missing_entry_combined    0.05\n",
      "JSD, SD=100    missing_entry_combined    0.1\n",
      "JSD, SD=100    missing_entry_combined    0.5\n",
      "CCEu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "CCEu, SD=100    activation_types    ['relu']\n",
      "CCEu, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "CCEu, SD=100    activation_types    ['sin', 'cos', 'linear']\n",
      "CCEu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "CCEu, SD=100    input_layer_type    dense\n",
      "CCEu, SD=100    input_layer_type    gaussian_noise\n",
      "CCEu, SD=100    input_layer_type    gaussian_dropout\n",
      "CCEu, SD=100    input_layer_type    sqrt_softmax\n",
      "CCEu, SD=100    input_layer_type    gaussian_kernel\n",
      "CCEu, SD=100    input_layer_type    CNN\n",
      "CCEu, SD=100    input_layer_type    VAE\n",
      "CCEu, SD=100    encoding_dim    2\n",
      "CCEu, SD=100    encoding_dim    3\n",
      "CCEu, SD=100    encoding_dim    6\n",
      "CCEu, SD=100    hidden_layers    3\n",
      "CCEu, SD=100    hidden_layers    5\n",
      "CCEu, SD=100    hidden_layers    7\n",
      "CCEu, SD=100    hidden_layers    9\n",
      "CCEu, SD=100    hidden_layers    27\n",
      "CCEu, SD=100    activity_regularizer    \n",
      "CCEu, SD=100    activity_regularizer    L2: 0.01\n",
      "CCEu, SD=100    activity_regularizer    L2: 10^-4\n",
      "CCEu, SD=100    activity_regularizer    L1: 0.01\n",
      "CCEu, SD=100    activity_regularizer    L1: 10^-4\n",
      "CCEu, SD=100    sigma    0.01/SD\n",
      "CCEu, SD=100    sigma    (0.01*4)/SD\n",
      "CCEu, SD=100    sigma    0.01/math.sqrt(SD)\n",
      "CCEu, SD=100    sigma    0.01\n",
      "CCEu, SD=100    sigma    0.05\n",
      "CCEu, SD=100    sigma    0.1\n",
      "CCEu, SD=100    sigma    0.2\n",
      "CCEu, SD=100    BN_size    2\n",
      "CCEu, SD=100    BN_size    3\n",
      "CCEu, SD=100    BN_size    4\n",
      "CCEu, SD=100    BN_size    5\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.01/SD\n",
      "CCEu, SD=100    gaussian_noise_sigma    (0.01*4)/SD\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.01\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.05\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.1\n",
      "CCEu, SD=100    gaussian_noise_sigma    0.2\n",
      "CCEu, SD=100    missing_entry    0.001\n",
      "CCEu, SD=100    missing_entry    0.005\n",
      "CCEu, SD=100    missing_entry    0.01\n",
      "CCEu, SD=100    missing_entry    0.05\n",
      "CCEu, SD=100    missing_entry    0.1\n",
      "CCEu, SD=100    missing_entry    0.5\n",
      "CCEu, SD=100    missing_entry_combined    0.001\n",
      "CCEu, SD=100    missing_entry_combined    0.005\n",
      "CCEu, SD=100    missing_entry_combined    0.01\n",
      "CCEu, SD=100    missing_entry_combined    0.05\n",
      "CCEu, SD=100    missing_entry_combined    0.1\n",
      "CCEu, SD=100    missing_entry_combined    0.5\n",
      "JSDu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n",
      "JSDu, SD=100    activation_types    ['relu']\n",
      "JSDu, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "JSDu, SD=100    activation_types    ['sin', 'cos', 'linear']\n",
      "JSDu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n",
      "JSDu, SD=100    input_layer_type    dense\n",
      "JSDu, SD=100    input_layer_type    gaussian_noise\n",
      "JSDu, SD=100    input_layer_type    gaussian_dropout\n",
      "JSDu, SD=100    input_layer_type    sqrt_softmax\n",
      "JSDu, SD=100    input_layer_type    gaussian_kernel\n",
      "JSDu, SD=100    input_layer_type    CNN\n",
      "JSDu, SD=100    input_layer_type    VAE\n",
      "JSDu, SD=100    encoding_dim    2\n",
      "JSDu, SD=100    encoding_dim    3\n",
      "JSDu, SD=100    encoding_dim    6\n",
      "JSDu, SD=100    hidden_layers    3\n",
      "JSDu, SD=100    hidden_layers    5\n",
      "JSDu, SD=100    hidden_layers    7\n",
      "JSDu, SD=100    hidden_layers    9\n",
      "JSDu, SD=100    hidden_layers    27\n",
      "JSDu, SD=100    activity_regularizer    \n",
      "JSDu, SD=100    activity_regularizer    L2: 0.01\n",
      "JSDu, SD=100    activity_regularizer    L2: 10^-4\n",
      "JSDu, SD=100    activity_regularizer    L1: 0.01\n",
      "JSDu, SD=100    activity_regularizer    L1: 10^-4\n",
      "JSDu, SD=100    sigma    0.01/SD\n",
      "JSDu, SD=100    sigma    (0.01*4)/SD\n",
      "JSDu, SD=100    sigma    0.01/math.sqrt(SD)\n",
      "JSDu, SD=100    sigma    0.01\n",
      "JSDu, SD=100    sigma    0.05\n",
      "JSDu, SD=100    sigma    0.1\n",
      "JSDu, SD=100    sigma    0.2\n",
      "JSDu, SD=100    BN_size    2\n",
      "JSDu, SD=100    BN_size    3\n",
      "JSDu, SD=100    BN_size    4\n",
      "JSDu, SD=100    BN_size    5\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.01/SD\n",
      "JSDu, SD=100    gaussian_noise_sigma    (0.01*4)/SD\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.01/math.sqrt(SD)\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.01\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.05\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.1\n",
      "JSDu, SD=100    gaussian_noise_sigma    0.2\n",
      "JSDu, SD=100    missing_entry    0.001\n",
      "JSDu, SD=100    missing_entry    0.005\n",
      "JSDu, SD=100    missing_entry    0.01\n",
      "JSDu, SD=100    missing_entry    0.05\n",
      "JSDu, SD=100    missing_entry    0.1\n",
      "JSDu, SD=100    missing_entry    0.5\n",
      "JSDu, SD=100    missing_entry_combined    0.001\n",
      "JSDu, SD=100    missing_entry_combined    0.005\n",
      "JSDu, SD=100    missing_entry_combined    0.01\n",
      "JSDu, SD=100    missing_entry_combined    0.05\n",
      "JSDu, SD=100    missing_entry_combined    0.1\n",
      "JSDu, SD=100    missing_entry_combined    0.5\n"
     ]
    }
   ],
   "source": [
    "experiments = []\n",
    "experiment_config_list = []\n",
    "experiment_config_strings = []\n",
    "experiment_config_results=[]\n",
    "experiment_config_results2=[]\n",
    "\n",
    "def load_from_csv(input_string):\n",
    "    with open(input_string, 'r') as fp:\n",
    "        reader = csv.reader(fp)\n",
    "        li = list(reader)\n",
    "    newlist = []\n",
    "    for row in li:\n",
    "        newrow = []\n",
    "        for entry in row [1:]:\n",
    "            newrow.append(float(entry))\n",
    "        newlist.append(newrow)\n",
    "    return newlist    \n",
    "\n",
    "def find(inputlist,search,key=lambda z: z):\n",
    "    for i in range(len(inputlist)):\n",
    "        if key(inputlist[i])==search:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def str_noneguard(obj):\n",
    "    if hasattr(obj,'__name__'):\n",
    "        return obj.__name__\n",
    "    if obj is None:\n",
    "        return ''\n",
    "    if isinstance(obj,list):\n",
    "        return str([str_noneguard(x) for x in obj])\n",
    "    return str(obj)\n",
    "\n",
    "def freeze(d):\n",
    "    # thanks to https://stackoverflow.com/a/13264725\n",
    "    if isinstance(d, dict):\n",
    "        return frozenset((key, freeze(value)) for key, value in d.items())\n",
    "    elif isinstance(d, list):\n",
    "        return tuple(freeze(value) for value in d)\n",
    "    return d\n",
    "\n",
    "def gen_experiment(config_string,input_dict={},parameter=None,vars=None):\n",
    "    if parameter is None:\n",
    "        vars = [None]\n",
    "    \n",
    "    for x in vars:\n",
    "        if (x is None or x=='default') and (not parameter is None):\n",
    "            x=defaults[parameter]\n",
    "\n",
    "        new_experiment_config=input_dict.copy()\n",
    "        if parameter=='input_layer_type' and x=='VAE':\n",
    "            new_experiment_config['VAE']=True\n",
    "        elif parameter=='input_layer_type' and x=='CNN':\n",
    "            new_experiment_config['CNN']=True\n",
    "        elif parameter=='missing_entry':\n",
    "            new_experiment_config['use_missing_entry']=True\n",
    "            new_experiment_config['use_gaussian_noise']=False\n",
    "            new_experiment_config['missing_entry_prob']=x\n",
    "        elif parameter=='missing_entry_combined':\n",
    "            new_experiment_config['use_missing_entry']=True\n",
    "            new_experiment_config['use_gaussian_noise']=True\n",
    "            new_experiment_config['missing_entry_prob']=x           \n",
    "        elif parameter=='kernel_landmarks':\n",
    "            new_experiment_config['input_layer_type']='gaussian_kernel'\n",
    "            new_experiment_config[parameter]=x\n",
    "        elif parameter=='CNN_kernel_size' or parameter=='CNN_filters':\n",
    "            new_experiment_config['CNN']=True\n",
    "            new_experiment_config[parameter]=x\n",
    "        elif parameter=='gaussian_noise_sigma':\n",
    "            new_experiment_config['input_layer_type']='gaussian_noise'\n",
    "            new_experiment_config[parameter]=x\n",
    "        elif parameter is not None:\n",
    "            new_experiment_config[parameter]=x\n",
    "        \n",
    "        \n",
    "        full_string=str(config_string + \"    \" + str_noneguard(parameter) + \"    \" + str_noneguard(x))\n",
    "        \n",
    "        if new_experiment_config in experiment_config_list:\n",
    "            mapping = experiment_config_list.index(new_experiment_config)\n",
    "#             experiments_mapping.append(mapping)\n",
    "        else:\n",
    "            mapping = len(experiment_config_list)\n",
    "#             experiments_mapping.append(mapping)\n",
    "            experiment_config_list.append(new_experiment_config)\n",
    "            experiment_config_strings.append(full_string)\n",
    "            experiment_config_results.append([])\n",
    "            experiment_config_results2.append([])\n",
    "            \n",
    "        experiments.append({'config_string':config_string,'input_dict':input_dict,'parameter':parameter,'vars':vars,'current_var':x,'config':new_experiment_config,'full_string':full_string,'mapping':mapping})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ground_config_strings = [\"JSD, SD=4\"]\n",
    "ground_config_strings = [\"CCE, SD=4\", \"JSD, SD=4\",\"CCEu, SD=4\", \"JSDu, SD=4\", \"CCE, SD=100\", \"JSD, SD=100\",\"CCEu, SD=100\", \"JSDu, SD=100\"]\n",
    "\n",
    "\n",
    "for config_string in ground_config_strings:    \n",
    "    ground_config = defaults.copy()\n",
    "    if \"CCE\" in config_string:\n",
    "        ground_config['loss_function'] = 'CCE'\n",
    "    elif \"JSD\" in config_string:\n",
    "        ground_config['loss_function'] = 'JSD'\n",
    "    elif \"MSE\" in config_string:\n",
    "        ground_config['loss_function'] = 'MSE'     \n",
    "    elif \"KLD\" in config_string:\n",
    "        ground_config['loss_function'] = 'KLD'    \n",
    "        \n",
    "    if \"u,\" in config_string:\n",
    "        ground_config['training_method'] = 'unsupervised'\n",
    "    if \"SD=100\" in config_string:\n",
    "        ground_config['sampling_density'] = 100\n",
    "    if \"(5)\" in config_string:\n",
    "        ground_config['hidden_layers'] = 5\n",
    "    \n",
    "    \n",
    "    if ground_config['training_method'] != 'unsupervised':\n",
    "        gen_experiment(config_string,ground_config,'training_method',[\"supervised\",\"supervised_2_percent\",\"semi\",\"semi_sup_first\",\"semi_mixed\",\"unsupervised\"])\n",
    "        \n",
    "    if ground_config['loss_function'] == 'MSE' or ground_config['loss_function'] == 'KLD':\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    activation_list = [defaults['activation_types'], ['relu'],['relu']*5, [keras.backend.sin,keras.backend.cos, keras.activations.linear],[keras.backend.sin,keras.backend.cos,keras.activations.linear, 'relu', 'sigmoid']]\n",
    "    gen_experiment(config_string,ground_config,'activation_types',activation_list)\n",
    "    \n",
    "    gen_experiment(config_string,ground_config,'input_layer_type',['dense','gaussian_noise','gaussian_dropout','sqrt_softmax','gaussian_kernel','CNN','VAE'])\n",
    "    gen_experiment(config_string,ground_config,'encoding_dim',[2,3,6])\n",
    "    gen_experiment(config_string,ground_config,'hidden_layers',[3,5,7,9,27])\n",
    "    \n",
    "    regularizer_list = ['default',keras.regularizers.l2(0.01),keras.regularizers.l2(10**-4),keras.regularizers.l1(0.01),keras.regularizers.l1(10**-4)]\n",
    "    regularizer_strings=[\"none\",\"L2: 0.01\",\"L2: 10^-4\",\"L1: 0.01\",\"L1: 10^-4\"]\n",
    "    for i in range(len(regularizer_list)):\n",
    "        try:\n",
    "            regularizer_list[i].__name__ = regularizer_strings[i]\n",
    "        except:\n",
    "            pass\n",
    "    gen_experiment(config_string,ground_config,'activity_regularizer',regularizer_list)\n",
    "    \n",
    "    \n",
    "    sigma_list=[lambda SD: 0.01/SD, lambda SD: (0.01*4)/SD, lambda SD: 0.01/math.sqrt(SD), lambda SD: 0.01, lambda SD: 0.05, lambda SD: 0.1, lambda SD: 0.2]\n",
    "    sigma_strings=[\"0.01/SD\", \"(0.01*4)/SD\", \"0.01/math.sqrt(SD)\", \"0.01\", \"0.05\", \"0.1\", \"0.2\"]\n",
    "    for i in range(len(sigma_list)):\n",
    "        sigma_list[i].__name__ = sigma_strings[i]\n",
    "    gen_experiment(config_string,ground_config,'sigma',sigma_list)\n",
    "\n",
    "    if ground_config['sampling_density']==100:\n",
    "        gen_experiment(config_string,ground_config,'BN_size',[2,3,4,5])\n",
    "    else:\n",
    "        gen_experiment(config_string,ground_config,'BN_size',[2,3,4,5,10,20,30])\n",
    "        \n",
    "    if ground_config['training_method'] != 'unsupervised':\n",
    "        gen_experiment(config_string,ground_config,'labeled_data_percentage',[99,50,20,10,5,2,1,0.5,0.25,0.125,0.05,0.01])\n",
    "    \n",
    "    # gen_experiment(config_string,ground_config,'kernel_landmarks',[3,10,25,50,100,200,500,1000])\n",
    "\n",
    "    \n",
    "    # if ground_config['sampling_density']>=100:\n",
    "    #     gen_experiment(config_string,ground_config,'CNN_kernel_size',[1,3,5,7,9,100])\n",
    "    # else:\n",
    "    #     gen_experiment(config_string,ground_config,'CNN_kernel_size',[1,3,5,7,9]) \n",
    "    \n",
    "    # gen_experiment(config_string,ground_config,'CNN_filters',[16,32,64,128])\n",
    "    \n",
    "    if ground_config['sampling_density']!=100:\n",
    "        gen_experiment(config_string,ground_config,'sampling_density',[4,15,25,50,100,150,300])\n",
    "\n",
    "    gen_experiment(config_string,ground_config,'gaussian_noise_sigma',sigma_list)    \n",
    "    gen_experiment(config_string,ground_config,'missing_entry',[0.001,0.005,0.01,0.05,0.1,0.5])\n",
    "    gen_experiment(config_string,ground_config,'missing_entry_combined',[0.001,0.005,0.01,0.05,0.1,0.5])   \n",
    "\n",
    "\n",
    "\n",
    "if LOAD_DATA:\n",
    "    try:\n",
    "        experiment_config_results = load_from_csv(\"experiment_config_results.csv\")\n",
    "        experiment_config_results2 = load_from_csv(\"experiment_config_results2.csv\")            \n",
    "    except:\n",
    "        print(\"Couldn't load data\")\n",
    "\n",
    "print(\"Experiments: \" + str(len(experiments)))\n",
    "print(\"Experiment configs: \" + str(len(experiment_config_list)))\n",
    "print(\"\\n\\n\\n----------DONE---------\\n\\n\\n\")\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(experiment['full_string'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dispatch.add_dispatch_support\n",
    "def JSD(y_true,y_pred):\n",
    "#     y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "#     y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "#     y_true = keras.backend.clip(y_true, keras.backend.epsilon(), 1)\n",
    "#     y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1)   \n",
    "    y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "    y_true = keras.backend.clip(y_true, keras.backend.epsilon(), 1)\n",
    "    y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1)\n",
    "    means = 0.5 * (y_true + y_pred)\n",
    "    divergence_tensor = 0.5 * keras.losses.kld(y_true, means) + 0.5 * keras.losses.kld(y_pred, means)\n",
    "        \n",
    "\n",
    "    return divergence_tensor\n",
    "\n",
    "def generate_samplespace(function,x_min,x_max,measurements):\n",
    "    non_normalized = [function(x) for x in np.linspace(x_min,x_max,measurements)]\n",
    "    return (non_normalized / sum(non_normalized))\n",
    "\n",
    "def normalize_df(df):\n",
    "    return df.div(df.sum(axis=1), axis=0)\n",
    "#     return df.subtract(df.min(axis=1), axis=0).div(df.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "def prob_distance(x,y):\n",
    "    xt=x.T # this is bad practice, but I cannot debug the statements below without doing this\n",
    "    yt=y.T\n",
    "    res= scipy.spatial.distance.jensenshannon(xt,yt,base=2.0)\n",
    "    res2=JSD(x,y)\n",
    "    return res,res2\n",
    "\n",
    "def make_bn(BN_size,sampling_density):\n",
    "    bn=gum.BayesNet(\"Quasi-Continuous\")\n",
    "    a=bn.add(gum.LabelizedVariable(\"A\",\"A binary variable\",2))\n",
    "    bn.cpt(a)[:]=[0.4, 0.6]\n",
    "\n",
    "    if BN_size>1:\n",
    "        b=bn.add(gum.RangeVariable(\"B\",\"A range variable\",0,sampling_density-1))\n",
    "        bn.addArc(a,b)\n",
    "        first = generate_samplespace(scipy.stats.norm().pdf,-10,3,sampling_density)\n",
    "        second = generate_samplespace(scipy.stats.norm().pdf,-2,6,sampling_density)\n",
    "        bn.cpt(b)[{'A':0}]=first\n",
    "        bn.cpt(b)[{'A':1}]=second\n",
    "\n",
    "\n",
    "    if BN_size>2:\n",
    "        c=bn.add(gum.RangeVariable(\"C\",\"Another quasi continuous variable\",0,sampling_density-1))\n",
    "        bn.addArc(b,c)\n",
    "        l=[]\n",
    "        for i in range(sampling_density):\n",
    "            # the size and the parameter of gamma depends on the parent value\n",
    "            k=(i*30.0)/sampling_density\n",
    "            l.append(generate_samplespace(scipy.stats.gamma(k+1).pdf,4,5+k,sampling_density))\n",
    "        bn.cpt(c)[:]=l\n",
    "\n",
    "\n",
    "        for d in range(BN_size-3):\n",
    "            # new variable\n",
    "            d=bn.add(gum.RangeVariable(\"D\"+str(d),\"Another quasi continuous variable\",0,sampling_density-1))\n",
    "            l=[]\n",
    "            bn.addArc(c,d)\n",
    "            for i in range(sampling_density):\n",
    "                # the size and the parameter of gamma depends on the parent value\n",
    "                k=(i*30.0)/sampling_density\n",
    "                l.append(generate_samplespace(scipy.stats.gamma(k+1).pdf,4,5+k,sampling_density))\n",
    "            bn.cpt(d)[:]=l\n",
    "\n",
    "    return bn\n",
    "\n",
    "def make_df(use_previous_df,bn,mu,sigma,use_gaussian_noise,use_missing_entry,missing_entry_prob):\n",
    "    if use_previous_df:\n",
    "        original_database=pd.read_csv(\"good_db.csv\")\n",
    "    else:\n",
    "        gum.generateCSV(bn,\"database.csv\",10000)\n",
    "        original_database=pd.read_csv(\"database.csv\")\n",
    "    original_database = original_database.reindex(sorted(original_database.columns), axis=1)\n",
    "\n",
    "\n",
    "    size_dict = {}\n",
    "    for column_name in original_database.columns:\n",
    "        size_dict[column_name] = bn.variable(column_name).domainSize()\n",
    "\n",
    "    shape = [original_database.shape[0],sum(size_dict.values())]\n",
    "\n",
    "    df_cols_sorted = sorted(list(original_database.columns))\n",
    "    sizes_sorted = [size_dict[x] for x in df_cols_sorted]\n",
    "    sizes_sorted_with_leading_zero = [0] + sizes_sorted\n",
    "\n",
    "    data=np.ones(original_database.shape[0]*original_database.shape[1])\n",
    "    row = list(range(original_database.shape[0]))*original_database.shape[1]\n",
    "    col = []\n",
    "    for i in range(original_database.values.T.shape[0]):\n",
    "        for item in original_database.values.T[i]:\n",
    "            col.append(item+sum(sizes_sorted_with_leading_zero[0:i+1]))\n",
    "    # print(col[20000])\n",
    "\n",
    "    \n",
    "    input3 = scipy.sparse.coo_matrix((data, (row, col)), shape=tuple(shape)).todense()\n",
    "\n",
    "    first_id2 = df_cols_sorted[:]\n",
    "    second_id2=[list(range(x)) for x in sizes_sorted]\n",
    "\n",
    "    arrays3=[np.repeat(first_id2,sizes_sorted) , [item for sublist in second_id2 for item in sublist]]\n",
    "    tuples2 = list(zip(*arrays3))\n",
    "    index2 = pd.MultiIndex.from_tuples(tuples2, names=['Variable', 'Value'])\n",
    "\n",
    "    hard_evidence = pd.DataFrame(input3,columns=index2)\n",
    "\n",
    "    df = hard_evidence + 0\n",
    "\n",
    "    if use_gaussian_noise:\n",
    "        noise = np.random.normal(mu, sigma, hard_evidence.shape) \n",
    "        df = df + noise\n",
    "        df = df.clip(lower=0,upper=1)\n",
    "    if use_missing_entry:\n",
    "        # TODO FIX\n",
    "        amount_of_variables = len(sizes_sorted)\n",
    "        rows=len(df)\n",
    "        total_entries=amount_of_variables*rows # amount of probability distributions in the PDB\n",
    "        missing_entry_nrs=np.random.choice(total_entries,size=round(total_entries*missing_entry_prob),replace=False)\n",
    "        m = missing_entry_nrs[:] # using an alias for shorter code\n",
    "        col_index=0\n",
    "        for attribute_nr,size in enumerate(sizes_sorted):\n",
    "            entries_this_col = m[  (m >= rows*attribute_nr )  &   (m < rows*(attribute_nr+1))      ]\n",
    "            rows_this_col = entries_this_col - (rows*attribute_nr)\n",
    "            df.iloc[rows_this_col,col_index:col_index+size] = 1\n",
    "\n",
    "            col_index+=size\n",
    "    \n",
    "    for col in df_cols_sorted:\n",
    "        df[col] = normalize_df(df[col])\n",
    "    \n",
    "    return df, hard_evidence, sizes_sorted\n",
    "\n",
    "# def vae_loss(z_mean, z_log_var,loss_func):\n",
    "#     # adapted from https://stackoverflow.com/a/61945712\n",
    "#     def loss(y_true, y_pred):\n",
    "#         # mse loss\n",
    "#         reconstruction_loss = loss_func(y_true, y_pred)\n",
    "#         # kl loss\n",
    "#         kl_loss = 1 + z_log_var - keras.backend.square(z_mean) - keras.backend.exp(z_log_var)\n",
    "#         kl_loss = keras.backend.sum(kl_loss, axis=-1)\n",
    "#         kl_loss *= -0.5\n",
    "#         weight = 0.\n",
    "#         return reconstruction_loss + (weight * kl_loss)\n",
    "#     return loss\n",
    "\n",
    "# def sampling(args):\n",
    "#     # adapted from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "#     z_mean, z_log_var = args\n",
    "#     #     batch = keras.backend.shape(z_mean)[0]\n",
    "#     # dim = keras.backend.int_shape(z_mean)[1]\n",
    "#     # epsilon = keras.backend.random_normal(shape=(batch, dim))\n",
    "#     batch = z_mean.shape[0]\n",
    "#     dim = z_mean.shape[1]\n",
    "\n",
    "#     # by default, random_normal has mean = 0 and std = 1.0\n",
    "#     epsilon = keras.backend.random_normal(shape=(dim,))\n",
    "#     thing = z_mean + keras.backend.exp(0.5 * z_log_var) * epsilon\n",
    "#     return thing\n",
    "\n",
    "class KLDivergenceLayer(keras.layers.Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "    # Adapted from https://tiao.io/post/tutorial-on-variational-autoencoders-with-a-concise-keras-implementation/\n",
    "    # I take no responsibility for this class\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * keras.backend.sum(1 + log_var -\n",
    "                                keras.backend.square(mu) -\n",
    "                                keras.backend.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(keras.backend.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs    \n",
    "    \n",
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE_model(keras.Model):\n",
    "    def __init__(self, encoder, decoder, loss_func, **kwargs):\n",
    "        super(VAE_model, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.loss_func = loss_func\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x,y = data\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "#             reconstruction_loss = self.loss_func(data, reconstruction)\n",
    "\n",
    "\n",
    "    \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "#             print(\"kl_loss before reduce mean\", kl_loss)\n",
    "#             print(\"kl_loss after reduce sum 1\", tf.reduce_sum(kl_loss, axis=1))\n",
    "#             print(\"kl_loss after reduce mean\", tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1)))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                    self.loss_func(y, reconstruction)\n",
    "            )\n",
    "                \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "def train_network(epochs,df,hard_evidence,activation_types,hidden_layers,encoding_dim,sizes_sorted,loss_function,training_method,activity_regularizer,input_layer_type,labeled_data_percentage,VAE,CNN,kernel_landmarks,CNN_layers,CNN_filters,CNN_kernel_size,gaussian_noise_sigma):\n",
    "    if training_method=='supervised' or training_method==\"unsupervised\":\n",
    "        x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(df,hard_evidence, test_size=0.2) #unsupervised\n",
    "    elif training_method==\"supervised_2_percent\":\n",
    "        x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(df,hard_evidence, test_size=0.98)\n",
    "    elif training_method==\"semi\" or training_method==\"semi_supervised\" or training_method==\"semisupervised\" or training_method==\"semi_sup_first\" or training_method==\"semi_mixed\":\n",
    "        x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(df,hard_evidence, test_size=labeled_data_percentage) # semi supervised\n",
    "        x_train_nolabel, x_test_nolabel, y_train_nolabel, y_test_nolabel = sklearn.model_selection.train_test_split(x_test,y_test,test_size=0.2) # semi supervised\n",
    "    else:\n",
    "        raise Exception(\"Invalid training method\")\n",
    "\n",
    "\n",
    "\n",
    "    x_train = np.float32(x_train)\n",
    "    x_test = np.float32(x_test)\n",
    "    y_train = np.float32(y_train)\n",
    "    y_test = np.float32(y_test)\n",
    "\n",
    "\n",
    "    # types = ['relu','relu','relu','relu','relu']\n",
    "    input_dim = sum(sizes_sorted)\n",
    "    # this is our input placeholder\n",
    "#     input_layer = keras.layers.Input(shape=(None,input_dim))\n",
    "    input_layer = keras.layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    if input_layer_type =='dense' and not CNN:\n",
    "        x = keras.layers.Dense(input_dim, activation='relu',activity_regularizer=activity_regularizer)(input_layer)\n",
    "    elif CNN:\n",
    "        x = tf.expand_dims(input_layer, axis=2)\n",
    "        x = keras.layers.Conv1D(input_shape=(0,input_dim),filters=CNN_filters, kernel_size=CNN_kernel_size, activation='relu')(x)\n",
    "        x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = keras.layers.Flatten()(x)\n",
    "\n",
    "    elif input_layer_type == 'gaussian_noise':    \n",
    "        x = keras.layers.GaussianNoise(gaussian_noise_sigma)(input_layer)\n",
    "    elif input_layer_type == 'gaussian_dropout':\n",
    "        x = keras.layers.GaussianDropout(0.01)(input_layer)\n",
    "    elif input_layer_type == 'sqrt_softmax':\n",
    "        x = keras.layers.Lambda(keras.backend.sqrt)(input_layer)\n",
    "        x= keras.layers.Softmax()(x)\n",
    "    elif input_layer_type == \"gaussian_kernel\":\n",
    "        \n",
    "        x = gkernel.GaussianKernel3(kernel_landmarks, input_dim)(input_layer)\n",
    "\n",
    "\n",
    "    encode_ratio=0.1\n",
    "    middle = hidden_layers//2\n",
    "    hidden_layer_list = []\n",
    "    for i in range(hidden_layers):\n",
    "        if CNN and i < CNN_layers-1:\n",
    "            \n",
    "            x = tf.expand_dims(x, axis=2)\n",
    "            x = keras.layers.Conv1D(filters=CNN_filters, kernel_size=CNN_kernel_size, activation='relu')(x)\n",
    "            x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "            x = keras.layers.Flatten()(x)\n",
    "            \n",
    "        elif VAE and i==middle:\n",
    "            \n",
    "            \n",
    "            z_mean = keras.layers.Dense(encoding_dim, name=\"z_mean\")(x)\n",
    "            z_log_var = keras.layers.Dense(encoding_dim, name=\"z_log_var\")(x)\n",
    "            z = Sampling()([z_mean, z_log_var])\n",
    "            latent_inputs = keras.layers.Input(shape=(encoding_dim,))\n",
    "            x = tf.add(latent_inputs,0)\n",
    "            \n",
    "        else:\n",
    "            ratio = 2**(math.log2(encode_ratio)+abs(i-middle))\n",
    "            size = encoding_dim if i==middle else max(( min(input_dim,int(ratio*input_dim))),encoding_dim)\n",
    "    #         print(size)\n",
    "            if len(activation_types)>1:\n",
    "                x = keras.layers.concatenate([keras.layers.Dense(size, activation=type,activity_regularizer=activity_regularizer)(x) for type in activation_types],axis=1)\n",
    "            else:\n",
    "                x = keras.layers.Dense(size, activation=activation_types[0],activity_regularizer=activity_regularizer)(x)\n",
    "        #     x = keras.layers.Dense(min(input_dim,int(ratio*input_dim)), activation='relu')(x)\n",
    "\n",
    "\n",
    "    final_layer_list= [keras.layers.Dense(size, activation='softmax',activity_regularizer=activity_regularizer)(x) for size in sizes_sorted]\n",
    "\n",
    "    decoded = keras.layers.concatenate(final_layer_list,axis=1)\n",
    "\n",
    "\n",
    "#     if VAE:\n",
    "#         kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "#         kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "\n",
    "    \n",
    "    if VAE:\n",
    "        encoder = keras.models.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "        decoder = keras.models.Model(latent_inputs, decoded, name=\"decoder\")\n",
    "        autoencoder = VAE_model(encoder, decoder,loss_function)\n",
    "        autoencoder.compile(optimizer='adam',metrics=['accuracy']) #semi supervised\n",
    "    else:\n",
    "        autoencoder = keras.models.Model(input_layer, outputs=decoded)\n",
    "        autoencoder.compile(optimizer='adam',loss=loss_function, metrics=['accuracy']) #semi supervised\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    hist = keras.callbacks.History()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[21]:\n",
    "#     if VAE:\n",
    "# #         decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "# #         decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "# #         h_decoded = decoder_h(z)\n",
    "# #         x_decoded_mean = decoder_mean(h_decoded)\n",
    "        \n",
    "# #         # end-to-end autoencoder\n",
    "# #         vae = Model(x, x_decoded_mean)\n",
    "\n",
    "#         # encoder, from inputs to latent space\n",
    "        \n",
    "\n",
    "\n",
    "#         # generator, from latent space to reconstructed inputs\n",
    "#         decoder_input = keras.layers.Input(shape=(encoding_dim,))\n",
    "#         x = decoder_input\n",
    "#         for i in range(middle+1,hidden_layers):\n",
    "#             ratio = 2**(math.log2(encode_ratio)+abs(i-middle))\n",
    "#             size = encoding_dim if i==middle else max(( min(input_dim,int(ratio*input_dim))),encoding_dim)\n",
    "#     #         print(size)\n",
    "#             if len(activation_types)>1:\n",
    "#                 x = keras.layers.concatenate([keras.layers.Dense(size, activation=type,activity_regularizer=activity_regularizer)(x) for type in activation_types],axis=1)\n",
    "#             else:\n",
    "#                 x = keras.layers.Dense(size, activation=activation_types[0],activity_regularizer=activity_regularizer)(x)\n",
    "\n",
    "#         final_layer_list_generator = [keras.layers.Dense(size, activation='softmax',activity_regularizer=activity_regularizer)(x) for size in sizes_sorted]\n",
    "#         decoded_generator = keras.layers.concatenate(final_layer_list_generator,axis=1)\n",
    "#         generator = keras.models.Model(decoder_input, outputs=decoded_generator)\n",
    "        \n",
    "#         old_loss_func = loss_function\n",
    "#         loss_function=vae_loss(z_mean, z_log_var,old_loss_func)\n",
    "#         autoencoder.compile(optimizer='adam',loss=loss_function, metrics=['accuracy'],run_eagerly=True) \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    if training_method=='supervised' or training_method==\"supervised_2_percent\":\n",
    "        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test, y_test), callbacks=[hist],verbose=verbosity)\n",
    "    elif training_method==\"semi\" or training_method==\"semi_supervised\" or training_method==\"semisupervised\":\n",
    "        # SEMI SUPERVISED\n",
    "        autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test_nolabel, x_test_nolabel), callbacks=[hist],verbose=verbosity)\n",
    "        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test, y_test), callbacks=[hist],verbose=verbosity)\n",
    "    elif training_method==\"unsupervised\":\n",
    "        # UNSUPERVISED\n",
    "        autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test, x_test), callbacks=[hist],verbose=verbosity)\n",
    "    elif training_method==\"semi_sup_first\":\n",
    "        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test, y_test), callbacks=[hist],verbose=verbosity)\n",
    "        autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, validation_data=(x_test_nolabel, x_test_nolabel), callbacks=[hist],verbose=verbosity)\n",
    "    elif training_method==\"semi_mixed\":\n",
    "        for i in range(epochs):\n",
    "            autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=1, batch_size=32, shuffle=True, validation_data=(x_test_nolabel, x_test_nolabel), callbacks=[hist],verbose=verbosity)\n",
    "            autoencoder.fit(x_train, y_train, epochs=1, batch_size=32, shuffle=True, validation_data=(x_test, y_test), callbacks=[hist],verbose=verbosity)\n",
    "    else:\n",
    "        raise Exception(\"Invalid training method\")\n",
    "    return autoencoder\n",
    "        \n",
    "def measure_performance(df, hard_evidence, autoencoder,sizes_sorted):\n",
    "    test_data = df.head(10000)\n",
    "    verify_data = hard_evidence.iloc[test_data.index]\n",
    "    results = pd.DataFrame(autoencoder.predict(test_data))\n",
    "\n",
    "\n",
    "\n",
    "    i=0\n",
    "    distances_before=[]\n",
    "    distances_before2=[]\n",
    "    distances_after=[]\n",
    "    distances_after2=[]\n",
    "    for size in sizes_sorted:\n",
    "        dist_before,dist_before2 = prob_distance(verify_data.iloc[:,i:i+size],test_data.iloc[:,i:i+size])\n",
    "        dist_after,dist_after2 = prob_distance(verify_data.iloc[:,i:i+size],results.iloc[:,i:i+size])\n",
    "        distances_before.append(np.nansum(dist_before))\n",
    "        distances_after.append(np.nansum(dist_after))\n",
    "        distances_before2.append(np.nansum(dist_before2))\n",
    "        distances_after2.append(np.nansum(dist_after2))        \n",
    "        i+=size\n",
    "\n",
    "    avg_distance_before = np.nansum(distances_before)\n",
    "    avg_distance_after = np.nansum(distances_after)\n",
    "    avg_distance_before2 = np.nansum(distances_before2)\n",
    "    avg_distance_after2 = np.nansum(distances_after2)   \n",
    "    improvement = avg_distance_before - avg_distance_after\n",
    "    improvement2 = avg_distance_before2 - avg_distance_after2\n",
    "    noise_left = 100*avg_distance_after/avg_distance_before\n",
    "    noise_left2 = 100*avg_distance_after2/avg_distance_before2\n",
    "    return noise_left, noise_left2\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss2(y_true,y_pred,sizes_sorted,loss_func):\n",
    "    i=0\n",
    "    total_loss = 0\n",
    "#     print(\"YEAH CUSTOM LOSS \" + str(loss_func))\n",
    "#     print(loss_func)\n",
    "    if loss_func=='JSD':\n",
    "        loss_func = JSD\n",
    "#         print(\"YEAH CUSTOM LOSS2 \" + str(loss_func))\n",
    "        for size in sizes_sorted:\n",
    "            total_loss += loss_func(y_true[:,i:i+size],y_pred[:,i:i+size])\n",
    "            i+=size\n",
    "        return total_loss\n",
    "    elif loss_func==\"CCE\":\n",
    "        loss_func = keras.losses.categorical_crossentropy\n",
    "    else:\n",
    "        loss_func = keras.losses.get(loss_func)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loss_list=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for size in sizes_sorted:\n",
    "        new_loss=loss_func(y_true[:,i:i+size],y_pred[:,i:i+size])\n",
    "        loss_list.append(new_loss)\n",
    "#         total_loss += new_loss\n",
    "        i+=size\n",
    "#     print(\"losses == loss list ????\", losses==loss_list)\n",
    "    good_loss = tf.math.add_n(loss_list)\n",
    "#     tf.print(total_loss - good_loss)\n",
    "#     display(good_loss2)\n",
    "#     print(total_loss)\n",
    "    return good_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- LOWEST RESULTS: 0, HIGHEST: 1 ------\n",
      "\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-46ae3d7c69de>\", line 45, in <module>\n",
      "    print(\"\\n\\n----- LOWEST RESULTS: \" + str(lowest_results) + \", HIGHEST: \"+ str(highest_results) + \" ------\\n\\n\")\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\", line 404, in write\n",
      "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\", line 205, in schedule\n",
      "    self._event_pipe.send(b'')\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\", line 491, in send\n",
      "    return super(Socket, self).send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 720, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 767, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 242, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\freek\\miniconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-46ae3d7c69de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#     highest_results = max([len(x) for x in experiment_configs_and_results.values()] )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n----- LOWEST RESULTS: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowest_results\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", HIGHEST: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhighest_results\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" ------\\n\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m451\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2053\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2054\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2054\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2057\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#-------------\n",
    "def run_experiment(epochs=epochs_default,use_previous_df=False,BN_size=BN_size_default,sampling_density=sampling_density_default,mu=mu_default,sigma=sigma_default,activation_types=activation_types_default,hidden_layers=hidden_layers_default,encoding_dim=encoding_dim_default,loss_function=loss_function_default,training_method=training_method_default,activity_regularizer=activity_regularizer_default,input_layer_type=input_layer_type_default,labeled_data_percentage=labeled_data_percentage_default, VAE=VAE_default,CNN=CNN_default,kernel_landmarks=kernel_landmarks_default,CNN_layers=CNN_layers_default,CNN_filters=CNN_filters_default,CNN_kernel_size=CNN_kernel_size_default,gaussian_noise_sigma=gaussian_noise_sigma_default,use_gaussian_noise=use_gaussian_noise_default,use_missing_entry=use_missing_entry_default,missing_entry_prob=missing_entry_prob_default):\n",
    "\n",
    "    if TEST_RUN_EPOCHS:\n",
    "        epochs=TEST_RUN_EPOCH_NR\n",
    "\n",
    "    bn = make_bn(BN_size,sampling_density)\n",
    "    sigma = sigma(sampling_density)\n",
    "    gaussian_noise_sigma=gaussian_noise_sigma(sampling_density)\n",
    "    df, hard_evidence, sizes_sorted = make_df(use_previous_df,bn,mu,sigma,use_gaussian_noise,use_missing_entry,missing_entry_prob)\n",
    "\n",
    "\n",
    "#     print(\"FIRST LOSS \" + str(loss_function))\n",
    "    \n",
    "    \n",
    "    if loss_function!='MSE':\n",
    "        old_loss=loss_function[:]\n",
    "        loss_function = lambda y_true,y_pred: custom_loss2(y_true,y_pred,sizes_sorted,old_loss)\n",
    "\n",
    "    labeled_data_percentage = (100-labeled_data_percentage)/100\n",
    "    \n",
    "\n",
    "\n",
    "#     print(\"SCOND LOSS \" + str(loss_function))\n",
    "    autoencoder =train_network(epochs,df,hard_evidence,activation_types,hidden_layers,encoding_dim,sizes_sorted,loss_function,training_method,activity_regularizer,input_layer_type,labeled_data_percentage, VAE,CNN,kernel_landmarks,CNN_layers,CNN_filters,CNN_kernel_size,gaussian_noise_sigma)\n",
    "    noise_left,noise_left2 = measure_performance(df, hard_evidence, autoencoder,sizes_sorted)\n",
    "    result = 100-noise_left\n",
    "    result2 = 100-noise_left2\n",
    "    del autoencoder\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    return result,result2\n",
    "\n",
    "    \n",
    "runs = 0\n",
    "lowest_results = 0\n",
    "    \n",
    "while True:\n",
    "    lowest_results = min([len(x) for x in experiment_config_results])\n",
    "    lowest_results_forcpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if (x['config']['sampling_density']*x['config']['BN_size'])<100])\n",
    "    lowest_results_forgpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if (x['config']['sampling_density']*x['config']['BN_size'])>=100])\n",
    "    highest_results = max([len(x) for x in experiment_config_results])\n",
    "#     lowest_results = min([len(x) for x in experiment_configs_and_results.values()] )\n",
    "#     highest_results = max([len(x) for x in experiment_configs_and_results.values()] )\n",
    "    print(\"\\n\\n----- LOWEST RESULTS: \" + str(lowest_results) + \", HIGHEST: \"+ str(highest_results) + \" ------\\n\\n\")\n",
    "    for i in reversed(range(451,len(experiments))):\n",
    "        experiment=experiments[i]\n",
    "        x=experiment\n",
    "        previous_runs = len(experiment_config_results[experiment['mapping']])\n",
    "        if previous_runs==lowest_results:\n",
    "        # if previous_runs==lowest_results_forcpu and (x['config']['sampling_density']*x['config']['BN_size'])<100:\n",
    "        # if previous_runs==lowest_results_forgpu and (x['config']['sampling_density']*x['config']['BN_size'])>=100:\n",
    "            if runs==0:\n",
    "                print(i)\n",
    "            result,result2 = run_experiment(**experiment['config'])\n",
    "            print(\"(\" + str(i) + \") \" + experiment['full_string'] + \";    \" + str(result) + \", \" + str(result2))\n",
    "            experiment_config_results[experiment['mapping']].append(result)\n",
    "            experiment_config_results2[experiment['mapping']].append(result2)\n",
    "#             experiment_configs_and_results[freeze(experiment['config'])].append(result)\n",
    "            if runs % 10 == 0 and runs>0:\n",
    "                clear_output(wait=True)\n",
    "            with open(\"experiments\", \"wb\") as dill_file:\n",
    "                dill.dump(experiments, dill_file)       \n",
    "            experiment_configs_csv = [[experiment_config_strings[i]] + experiment_config_results[i] for i in range(len(experiment_config_results))]\n",
    "            experiment_configs2_csv = [[experiment_config_strings[i]] + experiment_config_results2[i] for i in range(len(experiment_config_results))]\n",
    "            with open(\"experiment_config_results.csv\", \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(experiment_configs_csv)\n",
    "            with open(\"experiment_config_results2.csv\", \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(experiment_configs2_csv)                            \n",
    "            runs +=1\n",
    "    lowest_results = min([len(x) for x in experiment_config_results])\n",
    "    lowest_results_forcpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if (x['config']['sampling_density']*x['config']['BN_size'])<100])\n",
    "    lowest_results_forgpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if (x['config']['sampling_density']*x['config']['BN_size'])>=100])\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "#             np.savez(\"experiment_configs_and_results.npz\",experiment_configs_and_results)\n",
    "#             np.savez(\"experiments.npz\",experiments)\n",
    " \n",
    "    # TODO LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}