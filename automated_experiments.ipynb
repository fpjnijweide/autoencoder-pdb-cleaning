{"cells":[{"cell_type":"markdown","metadata":{},"source":["  # Automated experiments\n","\n","  This file runs all the experiments described in the paper. It will keep running until there are n=10 measurements for every configuration, which might take a few days. "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Settings\n","\n","USE_GPU = False # Turn on to use GPU and to append \"_gpu\" behind all saved files\n","\n","TEST_RUN_EPOCHS = False  # Whether to force the number of epochs below. Useful to test for errors without having to wait for hours of training\n","TEST_RUN_EPOCH_NR = 1\n","LOAD_DATA = True  # Whether to add results to previously saved .csv data\n","verbosity = 0\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Imports done\n"]}],"source":["get_ipython().run_line_magic('matplotlib', 'inline')\n","\n","import os\n","\n","if USE_GPU:\n","    gpu_string = \"_gpu\"\n","else:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n","    gpu_string = \"\"\n","\n","import csv\n","import tensorflow as tf\n","import scipy.stats\n","import scipy.spatial\n","import numpy as np\n","import tensorflow.keras as keras\n","import pyAgrum as gum\n","import pandas as pd\n","import sklearn.model_selection\n","import math\n","import gc\n","import gkernel  # gkernel.py in this folder\n","import dill\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import math_ops\n","\n","from IPython.display import clear_output\n","\n","print('Imports done')\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 3067252260834525113\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 11824660233650762014\nphysical_device_desc: \"device: XLA_CPU device\"\n]\n2.3.0\nNum GPUs Available: 0\nWARNING:tensorflow:From <ipython-input-3-2ec240d8b942>:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.config.list_physical_devices('GPU')` instead.\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":3}],"source":["from tensorflow.python.client import device_lib\n","\n","print(device_lib.list_local_devices())\n","print(tf.__version__)\n","print(\"Num GPUs Available: \" + str(len(tf.config.experimental.list_physical_devices('GPU'))))\n","tf.test.is_gpu_available()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # Default Variables for experiments.You probably want to use the cell above to change experiment vars.\n","BN_size_default = 3  # amount of BN variables, minimum 3\n","\n","mu_default = 0\n","sigma_default = 0.02  # Distribution of the noise\n","gaussian_noise_sigma_default = lambda SD: (0.01 / SD) * 100\n","sampling_density_default = 4  # How many bins the quasi-continuous variables use for distributing their probabilities. Higher_default = better approximation of continuous distributions\n","\n","activation_types_default = [keras.backend.sin, keras.backend.cos, keras.activations.linear, 'relu',\n","                            'swish']  # Activation layer types\n","hidden_layers_default = 3  # amount of hidden layers\n","encoding_dim_default = BN_size_default  # The dimensionality of the middle layer\n","loss_function_default = 'JSD'\n","training_method_default = 'semi'\n","\n","activity_regularizer_default = keras.regularizers.l2(10 ** -4)\n","activity_regularizer_default.__name__ = \"L2: 10^-4\"\n","\n","input_layer_type_default = 'gaussian_noise'\n","labeled_data_percentage_default = 2\n","\n","epochs_default = 100\n","VAE_default = False\n","CNN_default = False\n","kernel_landmarks_default = 100\n","\n","CNN_layers_default = 1\n","CNN_filters_default = 64\n","CNN_kernel_size_default = 3\n","\n","use_gaussian_noise_default = True\n","use_missing_entry_default = False\n","missing_entry_prob_default = 0.01\n","rows_default=10000\n","\n","defaults = dict(BN_size=BN_size_default, mu=mu_default, sigma=sigma_default, sampling_density=sampling_density_default,\n","                gaussian_noise_sigma=gaussian_noise_sigma_default, activation_types=activation_types_default,\n","                hidden_layers=hidden_layers_default, encoding_dim=encoding_dim_default,\n","                loss_function=loss_function_default, training_method=training_method_default,\n","                activity_regularizer=activity_regularizer_default, input_layer_type=input_layer_type_default,\n","                labeled_data_percentage=labeled_data_percentage_default, epochs=epochs_default, VAE=VAE_default,\n","                CNN=CNN_default, kernel_landmarks=kernel_landmarks_default, CNN_layers=CNN_layers_default,\n","                CNN_filters=CNN_filters_default, CNN_kernel_size=CNN_kernel_size_default,\n","                use_gaussian_noise=use_gaussian_noise_default, use_missing_entry=use_missing_entry_default,\n","                missing_entry_prob=missing_entry_prob_default,rows=rows_default)\n","\n","parameters = list(defaults.keys())\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["could not load data\n","Experiments: 378\n","Experiment configs: 334\n","\n","\n","\n","----------DONE---------\n","\n","\n","\n","CCE, SD=4    training_method    supervised\n","CCE, SD=4    training_method    supervised_2_percent\n","CCE, SD=4    training_method    semi\n","CCE, SD=4    training_method    semi_sup_first\n","CCE, SD=4    training_method    semi_mixed\n","CCE, SD=4    training_method    unsupervised\n","CCE, SD=4    labeled_data_percentage    99\n","CCE, SD=4    labeled_data_percentage    50\n","CCE, SD=4    labeled_data_percentage    20\n","CCE, SD=4    labeled_data_percentage    10\n","CCE, SD=4    labeled_data_percentage    5\n","CCE, SD=4    labeled_data_percentage    2\n","CCE, SD=4    labeled_data_percentage    1\n","CCE, SD=4    labeled_data_percentage    0.5\n","CCE, SD=4    labeled_data_percentage    0.25\n","CCE, SD=4    labeled_data_percentage    0.125\n","CCE, SD=4    labeled_data_percentage    0.05\n","CCE, SD=4    labeled_data_percentage    0.01\n","CCE, SD=4    sampling_density    4\n","CCE, SD=4    sampling_density    15\n","CCE, SD=4    sampling_density    25\n","CCE, SD=4    sampling_density    50\n","CCE, SD=4    sampling_density    100\n","CCE, SD=4    sampling_density    150\n","CCE, SD=4    sampling_density    300\n","JSD, SD=4    training_method    supervised\n","JSD, SD=4    training_method    supervised_2_percent\n","JSD, SD=4    training_method    semi\n","JSD, SD=4    training_method    semi_sup_first\n","JSD, SD=4    training_method    semi_mixed\n","JSD, SD=4    training_method    unsupervised\n","JSD, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n","JSD, SD=4    activation_types    ['relu']\n","JSD, SD=4    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n","JSD, SD=4    activation_types    ['sin', 'cos', 'linear']\n","JSD, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n","JSD, SD=4    input_layer_type    dense\n","JSD, SD=4    input_layer_type    gaussian_noise\n","JSD, SD=4    input_layer_type    gaussian_dropout\n","JSD, SD=4    input_layer_type    sqrt_softmax\n","JSD, SD=4    input_layer_type    gaussian_kernel\n","JSD, SD=4    input_layer_type    CNN\n","JSD, SD=4    input_layer_type    VAE\n","JSD, SD=4    encoding_dim    2\n","JSD, SD=4    encoding_dim    3\n","JSD, SD=4    encoding_dim    6\n","JSD, SD=4    hidden_layers    3\n","JSD, SD=4    hidden_layers    5\n","JSD, SD=4    hidden_layers    7\n","JSD, SD=4    hidden_layers    9\n","JSD, SD=4    hidden_layers    27\n","JSD, SD=4    activity_regularizer    \n","JSD, SD=4    activity_regularizer    L2: 0.01\n","JSD, SD=4    activity_regularizer    L2: 10^-4\n","JSD, SD=4    activity_regularizer    L1: 0.01\n","JSD, SD=4    activity_regularizer    L1: 10^-4\n","JSD, SD=4    sigma    0.005\n","JSD, SD=4    sigma    0.01\n","JSD, SD=4    sigma    0.02\n","JSD, SD=4    sigma    0.05\n","JSD, SD=4    sigma    0.1\n","JSD, SD=4    sigma    0.2\n","JSD, SD=4    BN_size    2\n","JSD, SD=4    BN_size    3\n","JSD, SD=4    BN_size    4\n","JSD, SD=4    BN_size    5\n","JSD, SD=4    BN_size    10\n","JSD, SD=4    BN_size    20\n","JSD, SD=4    BN_size    30\n","JSD, SD=4    labeled_data_percentage    99\n","JSD, SD=4    labeled_data_percentage    50\n","JSD, SD=4    labeled_data_percentage    20\n","JSD, SD=4    labeled_data_percentage    10\n","JSD, SD=4    labeled_data_percentage    5\n","JSD, SD=4    labeled_data_percentage    2\n","JSD, SD=4    labeled_data_percentage    1\n","JSD, SD=4    labeled_data_percentage    0.5\n","JSD, SD=4    labeled_data_percentage    0.25\n","JSD, SD=4    labeled_data_percentage    0.125\n","JSD, SD=4    labeled_data_percentage    0.05\n","JSD, SD=4    labeled_data_percentage    0.01\n","JSD, SD=4    sampling_density    4\n","JSD, SD=4    sampling_density    15\n","JSD, SD=4    sampling_density    25\n","JSD, SD=4    sampling_density    50\n","JSD, SD=4    sampling_density    100\n","JSD, SD=4    sampling_density    150\n","JSD, SD=4    sampling_density    300\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: 0.01\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: 0.02\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: 0.05\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: 0.1\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: 0.2\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: (0.01/SD)*100\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: (0.02/SD)*100\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: (0.05/SD)*100\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: (0.1/SD)*100\n","JSD, SD=4    gaussian_noise_sigma    lambda SD: (0.2/SD)*100\n","JSD, SD=4    missing_entry    0.001\n","JSD, SD=4    missing_entry    0.005\n","JSD, SD=4    missing_entry    0.01\n","JSD, SD=4    missing_entry    0.05\n","JSD, SD=4    missing_entry    0.1\n","JSD, SD=4    missing_entry    0.5\n","JSD, SD=4    missing_entry_combined    0.001\n","JSD, SD=4    missing_entry_combined    0.005\n","JSD, SD=4    missing_entry_combined    0.01\n","JSD, SD=4    missing_entry_combined    0.05\n","JSD, SD=4    missing_entry_combined    0.1\n","JSD, SD=4    missing_entry_combined    0.5\n","JSD, SD=4    missing_entry_no_denoising    0.001\n","JSD, SD=4    missing_entry_no_denoising    0.005\n","JSD, SD=4    missing_entry_no_denoising    0.01\n","JSD, SD=4    missing_entry_no_denoising    0.05\n","JSD, SD=4    missing_entry_no_denoising    0.1\n","JSD, SD=4    missing_entry_no_denoising    0.5\n","JSD, SD=4    rows    100\n","JSD, SD=4    rows    1000\n","JSD, SD=4    rows    10000\n","JSD, SD=4    rows    100000\n","JSD, SD=4    rows    1000000\n","CCEu, SD=4    sampling_density    4\n","CCEu, SD=4    sampling_density    15\n","CCEu, SD=4    sampling_density    25\n","CCEu, SD=4    sampling_density    50\n","CCEu, SD=4    sampling_density    100\n","CCEu, SD=4    sampling_density    150\n","CCEu, SD=4    sampling_density    300\n","JSDu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n","JSDu, SD=4    activation_types    ['relu']\n","JSDu, SD=4    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n","JSDu, SD=4    activation_types    ['sin', 'cos', 'linear']\n","JSDu, SD=4    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n","JSDu, SD=4    input_layer_type    dense\n","JSDu, SD=4    input_layer_type    gaussian_noise\n","JSDu, SD=4    input_layer_type    gaussian_dropout\n","JSDu, SD=4    input_layer_type    sqrt_softmax\n","JSDu, SD=4    input_layer_type    gaussian_kernel\n","JSDu, SD=4    input_layer_type    CNN\n","JSDu, SD=4    input_layer_type    VAE\n","JSDu, SD=4    encoding_dim    2\n","JSDu, SD=4    encoding_dim    3\n","JSDu, SD=4    encoding_dim    6\n","JSDu, SD=4    hidden_layers    3\n","JSDu, SD=4    hidden_layers    5\n","JSDu, SD=4    hidden_layers    7\n","JSDu, SD=4    hidden_layers    9\n","JSDu, SD=4    hidden_layers    27\n","JSDu, SD=4    activity_regularizer    \n","JSDu, SD=4    activity_regularizer    L2: 0.01\n","JSDu, SD=4    activity_regularizer    L2: 10^-4\n","JSDu, SD=4    activity_regularizer    L1: 0.01\n","JSDu, SD=4    activity_regularizer    L1: 10^-4\n","JSDu, SD=4    sigma    0.005\n","JSDu, SD=4    sigma    0.01\n","JSDu, SD=4    sigma    0.02\n","JSDu, SD=4    sigma    0.05\n","JSDu, SD=4    sigma    0.1\n","JSDu, SD=4    sigma    0.2\n","JSDu, SD=4    BN_size    2\n","JSDu, SD=4    BN_size    3\n","JSDu, SD=4    BN_size    4\n","JSDu, SD=4    BN_size    5\n","JSDu, SD=4    BN_size    10\n","JSDu, SD=4    BN_size    20\n","JSDu, SD=4    BN_size    30\n","JSDu, SD=4    sampling_density    4\n","JSDu, SD=4    sampling_density    15\n","JSDu, SD=4    sampling_density    25\n","JSDu, SD=4    sampling_density    50\n","JSDu, SD=4    sampling_density    100\n","JSDu, SD=4    sampling_density    150\n","JSDu, SD=4    sampling_density    300\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: 0.01\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: 0.02\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: 0.05\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: 0.1\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: 0.2\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: (0.01/SD)*100\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: (0.02/SD)*100\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: (0.05/SD)*100\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: (0.1/SD)*100\n","JSDu, SD=4    gaussian_noise_sigma    lambda SD: (0.2/SD)*100\n","JSDu, SD=4    missing_entry    0.001\n","JSDu, SD=4    missing_entry    0.005\n","JSDu, SD=4    missing_entry    0.01\n","JSDu, SD=4    missing_entry    0.05\n","JSDu, SD=4    missing_entry    0.1\n","JSDu, SD=4    missing_entry    0.5\n","JSDu, SD=4    missing_entry_combined    0.001\n","JSDu, SD=4    missing_entry_combined    0.005\n","JSDu, SD=4    missing_entry_combined    0.01\n","JSDu, SD=4    missing_entry_combined    0.05\n","JSDu, SD=4    missing_entry_combined    0.1\n","JSDu, SD=4    missing_entry_combined    0.5\n","JSDu, SD=4    missing_entry_no_denoising    0.001\n","JSDu, SD=4    missing_entry_no_denoising    0.005\n","JSDu, SD=4    missing_entry_no_denoising    0.01\n","JSDu, SD=4    missing_entry_no_denoising    0.05\n","JSDu, SD=4    missing_entry_no_denoising    0.1\n","JSDu, SD=4    missing_entry_no_denoising    0.5\n","JSDu, SD=4    rows    100\n","JSDu, SD=4    rows    1000\n","JSDu, SD=4    rows    10000\n","JSDu, SD=4    rows    100000\n","JSDu, SD=4    rows    1000000\n","CCE, SD=100    training_method    supervised\n","CCE, SD=100    training_method    supervised_2_percent\n","CCE, SD=100    training_method    semi\n","CCE, SD=100    training_method    semi_sup_first\n","CCE, SD=100    training_method    semi_mixed\n","CCE, SD=100    training_method    unsupervised\n","CCE, SD=100    labeled_data_percentage    99\n","CCE, SD=100    labeled_data_percentage    50\n","CCE, SD=100    labeled_data_percentage    20\n","CCE, SD=100    labeled_data_percentage    10\n","CCE, SD=100    labeled_data_percentage    5\n","CCE, SD=100    labeled_data_percentage    2\n","CCE, SD=100    labeled_data_percentage    1\n","CCE, SD=100    labeled_data_percentage    0.5\n","CCE, SD=100    labeled_data_percentage    0.25\n","CCE, SD=100    labeled_data_percentage    0.125\n","CCE, SD=100    labeled_data_percentage    0.05\n","CCE, SD=100    labeled_data_percentage    0.01\n","JSD, SD=100    training_method    supervised\n","JSD, SD=100    training_method    supervised_2_percent\n","JSD, SD=100    training_method    semi\n","JSD, SD=100    training_method    semi_sup_first\n","JSD, SD=100    training_method    semi_mixed\n","JSD, SD=100    training_method    unsupervised\n","JSD, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n","JSD, SD=100    activation_types    ['relu']\n","JSD, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n","JSD, SD=100    activation_types    ['sin', 'cos', 'linear']\n","JSD, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n","JSD, SD=100    input_layer_type    dense\n","JSD, SD=100    input_layer_type    gaussian_noise\n","JSD, SD=100    input_layer_type    gaussian_dropout\n","JSD, SD=100    input_layer_type    sqrt_softmax\n","JSD, SD=100    input_layer_type    gaussian_kernel\n","JSD, SD=100    input_layer_type    CNN\n","JSD, SD=100    input_layer_type    VAE\n","JSD, SD=100    encoding_dim    2\n","JSD, SD=100    encoding_dim    3\n","JSD, SD=100    encoding_dim    6\n","JSD, SD=100    hidden_layers    3\n","JSD, SD=100    hidden_layers    5\n","JSD, SD=100    hidden_layers    7\n","JSD, SD=100    hidden_layers    9\n","JSD, SD=100    hidden_layers    27\n","JSD, SD=100    activity_regularizer    \n","JSD, SD=100    activity_regularizer    L2: 0.01\n","JSD, SD=100    activity_regularizer    L2: 10^-4\n","JSD, SD=100    activity_regularizer    L1: 0.01\n","JSD, SD=100    activity_regularizer    L1: 10^-4\n","JSD, SD=100    sigma    0.005\n","JSD, SD=100    sigma    0.01\n","JSD, SD=100    sigma    0.02\n","JSD, SD=100    sigma    0.05\n","JSD, SD=100    sigma    0.1\n","JSD, SD=100    sigma    0.2\n","JSD, SD=100    BN_size    2\n","JSD, SD=100    BN_size    3\n","JSD, SD=100    BN_size    4\n","JSD, SD=100    BN_size    5\n","JSD, SD=100    labeled_data_percentage    99\n","JSD, SD=100    labeled_data_percentage    50\n","JSD, SD=100    labeled_data_percentage    20\n","JSD, SD=100    labeled_data_percentage    10\n","JSD, SD=100    labeled_data_percentage    5\n","JSD, SD=100    labeled_data_percentage    2\n","JSD, SD=100    labeled_data_percentage    1\n","JSD, SD=100    labeled_data_percentage    0.5\n","JSD, SD=100    labeled_data_percentage    0.25\n","JSD, SD=100    labeled_data_percentage    0.125\n","JSD, SD=100    labeled_data_percentage    0.05\n","JSD, SD=100    labeled_data_percentage    0.01\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: 0.01\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: 0.02\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: 0.05\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: 0.1\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: 0.2\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: (0.01/SD)*100\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: (0.02/SD)*100\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: (0.05/SD)*100\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: (0.1/SD)*100\n","JSD, SD=100    gaussian_noise_sigma    lambda SD: (0.2/SD)*100\n","JSD, SD=100    missing_entry    0.001\n","JSD, SD=100    missing_entry    0.005\n","JSD, SD=100    missing_entry    0.01\n","JSD, SD=100    missing_entry    0.05\n","JSD, SD=100    missing_entry    0.1\n","JSD, SD=100    missing_entry    0.5\n","JSD, SD=100    missing_entry_combined    0.001\n","JSD, SD=100    missing_entry_combined    0.005\n","JSD, SD=100    missing_entry_combined    0.01\n","JSD, SD=100    missing_entry_combined    0.05\n","JSD, SD=100    missing_entry_combined    0.1\n","JSD, SD=100    missing_entry_combined    0.5\n","JSD, SD=100    missing_entry_no_denoising    0.001\n","JSD, SD=100    missing_entry_no_denoising    0.005\n","JSD, SD=100    missing_entry_no_denoising    0.01\n","JSD, SD=100    missing_entry_no_denoising    0.05\n","JSD, SD=100    missing_entry_no_denoising    0.1\n","JSD, SD=100    missing_entry_no_denoising    0.5\n","JSD, SD=100    rows    100\n","JSD, SD=100    rows    1000\n","JSD, SD=100    rows    10000\n","JSD, SD=100    rows    100000\n","JSD, SD=100    rows    1000000\n","JSDu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'swish']\n","JSDu, SD=100    activation_types    ['relu']\n","JSDu, SD=100    activation_types    ['relu', 'relu', 'relu', 'relu', 'relu']\n","JSDu, SD=100    activation_types    ['sin', 'cos', 'linear']\n","JSDu, SD=100    activation_types    ['sin', 'cos', 'linear', 'relu', 'sigmoid']\n","JSDu, SD=100    input_layer_type    dense\n","JSDu, SD=100    input_layer_type    gaussian_noise\n","JSDu, SD=100    input_layer_type    gaussian_dropout\n","JSDu, SD=100    input_layer_type    sqrt_softmax\n","JSDu, SD=100    input_layer_type    gaussian_kernel\n","JSDu, SD=100    input_layer_type    CNN\n","JSDu, SD=100    input_layer_type    VAE\n","JSDu, SD=100    encoding_dim    2\n","JSDu, SD=100    encoding_dim    3\n","JSDu, SD=100    encoding_dim    6\n","JSDu, SD=100    hidden_layers    3\n","JSDu, SD=100    hidden_layers    5\n","JSDu, SD=100    hidden_layers    7\n","JSDu, SD=100    hidden_layers    9\n","JSDu, SD=100    hidden_layers    27\n","JSDu, SD=100    activity_regularizer    \n","JSDu, SD=100    activity_regularizer    L2: 0.01\n","JSDu, SD=100    activity_regularizer    L2: 10^-4\n","JSDu, SD=100    activity_regularizer    L1: 0.01\n","JSDu, SD=100    activity_regularizer    L1: 10^-4\n","JSDu, SD=100    sigma    0.005\n","JSDu, SD=100    sigma    0.01\n","JSDu, SD=100    sigma    0.02\n","JSDu, SD=100    sigma    0.05\n","JSDu, SD=100    sigma    0.1\n","JSDu, SD=100    sigma    0.2\n","JSDu, SD=100    BN_size    2\n","JSDu, SD=100    BN_size    3\n","JSDu, SD=100    BN_size    4\n","JSDu, SD=100    BN_size    5\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: 0.01\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: 0.02\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: 0.05\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: 0.1\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: 0.2\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: (0.01/SD)*100\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: (0.02/SD)*100\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: (0.05/SD)*100\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: (0.1/SD)*100\n","JSDu, SD=100    gaussian_noise_sigma    lambda SD: (0.2/SD)*100\n","JSDu, SD=100    missing_entry    0.001\n","JSDu, SD=100    missing_entry    0.005\n","JSDu, SD=100    missing_entry    0.01\n","JSDu, SD=100    missing_entry    0.05\n","JSDu, SD=100    missing_entry    0.1\n","JSDu, SD=100    missing_entry    0.5\n","JSDu, SD=100    missing_entry_combined    0.001\n","JSDu, SD=100    missing_entry_combined    0.005\n","JSDu, SD=100    missing_entry_combined    0.01\n","JSDu, SD=100    missing_entry_combined    0.05\n","JSDu, SD=100    missing_entry_combined    0.1\n","JSDu, SD=100    missing_entry_combined    0.5\n","JSDu, SD=100    missing_entry_no_denoising    0.001\n","JSDu, SD=100    missing_entry_no_denoising    0.005\n","JSDu, SD=100    missing_entry_no_denoising    0.01\n","JSDu, SD=100    missing_entry_no_denoising    0.05\n","JSDu, SD=100    missing_entry_no_denoising    0.1\n","JSDu, SD=100    missing_entry_no_denoising    0.5\n","JSDu, SD=100    rows    100\n","JSDu, SD=100    rows    1000\n","JSDu, SD=100    rows    10000\n","JSDu, SD=100    rows    100000\n","JSDu, SD=100    rows    1000000\n"]}],"source":["experiments = []\n","experiment_config_list = []\n","experiment_config_strings = []\n","experiment_config_results = []\n","\n","\n","def load_from_csv(input_string):\n","    with open(input_string, 'r') as fp:\n","        reader = csv.reader(fp)\n","        li = list(reader)\n","    newlist = []\n","    for row in li:\n","        newrow = []\n","        for entry in row[1:]:\n","            if entry == '':\n","                break\n","            else:\n","                newrow.append(float(entry))\n","        newlist.append(newrow)\n","    return newlist\n","\n","\n","def find(inputlist, search, key=lambda z: z):\n","    for i in range(len(inputlist)):\n","        if key(inputlist[i]) == search:\n","            return i\n","    return None\n","\n","\n","def str_noneguard(obj):\n","    if hasattr(obj, '__name__'):\n","        return obj.__name__\n","    if obj is None:\n","        return ''\n","    if isinstance(obj, list):\n","        return str([str_noneguard(x) for x in obj])\n","    return str(obj)\n","\n","\n","def freeze(d):\n","    # thanks to https://stackoverflow.com/a/13264725\n","    if isinstance(d, dict):\n","        return frozenset((key, freeze(value)) for key, value in d.items())\n","    elif isinstance(d, list):\n","        return tuple(freeze(value) for value in d)\n","    return d\n","\n","\n","def gen_experiment(config_string, input_dict={}, parameter=None, vars=None):\n","    if parameter is None:\n","        vars = [None]\n","\n","    for x in vars:\n","        if (not parameter=='activity_regularizer') and (x is None or x == 'default') and (not parameter is None):\n","            x = defaults[parameter]\n","\n","        new_experiment_config = input_dict.copy()\n","        if parameter == 'input_layer_type' and x == 'VAE':\n","            new_experiment_config['VAE'] = True\n","        elif parameter == 'input_layer_type' and x == 'CNN':\n","            new_experiment_config['CNN'] = True\n","        elif parameter == 'missing_entry':\n","            new_experiment_config['use_missing_entry'] = True\n","            new_experiment_config['use_gaussian_noise'] = False\n","            new_experiment_config['missing_entry_prob'] = x\n","        elif parameter == 'missing_entry_combined':\n","            new_experiment_config['use_missing_entry'] = True\n","            new_experiment_config['use_gaussian_noise'] = True\n","            new_experiment_config['missing_entry_prob'] = x\n","        elif parameter == 'missing_entry_no_denoising':\n","            new_experiment_config['use_missing_entry'] = True\n","            new_experiment_config['use_gaussian_noise'] = False\n","            new_experiment_config['input_layer_type'] = 'dense'\n","            new_experiment_config['missing_entry_prob'] = x\n","        elif parameter == 'kernel_landmarks':\n","            new_experiment_config['input_layer_type'] = 'gaussian_kernel'\n","            new_experiment_config[parameter] = x\n","        elif parameter == 'CNN_kernel_size' or parameter == 'CNN_filters':\n","            new_experiment_config['CNN'] = True\n","            new_experiment_config[parameter] = x\n","        elif parameter == 'gaussian_noise_sigma':\n","            new_experiment_config['input_layer_type'] = 'gaussian_noise'\n","            new_experiment_config[parameter] = x\n","        elif parameter is not None:\n","            new_experiment_config[parameter] = x\n","\n","        full_string = str(config_string + \"    \" + str_noneguard(parameter) + \"    \" + str_noneguard(x))\n","\n","        if new_experiment_config in experiment_config_list:\n","            mapping = experiment_config_list.index(new_experiment_config)\n","        else:\n","            mapping = len(experiment_config_list)\n","            experiment_config_list.append(new_experiment_config)\n","            experiment_config_strings.append(full_string)\n","            experiment_config_results.append([])\n","\n","        experiments.append(\n","            {'config_string': config_string, 'input_dict': input_dict, 'parameter': parameter, 'vars': vars,\n","             'current_var': x, 'config': new_experiment_config, 'full_string': full_string, 'mapping': mapping})\n","\n","\n","ground_config_strings = [\"CCE, SD=4\", \"JSD, SD=4\", \"CCEu, SD=4\", \"JSDu, SD=4\", \"CCE, SD=100\", \"JSD, SD=100\",\n","                         \"CCEu, SD=100\", \"JSDu, SD=100\"]\n","\n","for config_string in ground_config_strings:\n","    ground_config = defaults.copy()\n","    if \"CCE\" in config_string:\n","        ground_config['loss_function'] = 'CCE'\n","    elif \"JSD\" in config_string:\n","        ground_config['loss_function'] = 'JSD'\n","    elif \"MSE\" in config_string:\n","        ground_config['loss_function'] = 'MSE'\n","    elif \"KLD\" in config_string:\n","        ground_config['loss_function'] = 'KLD'\n","\n","    if \"u,\" in config_string:\n","        ground_config['training_method'] = 'unsupervised'\n","    if \"SD=100\" in config_string:\n","        ground_config['sampling_density'] = 100\n","\n","    # 0\n","    if ground_config['training_method'] != 'unsupervised':\n","        gen_experiment(config_string, ground_config, 'training_method',\n","                       [\"supervised\", \"supervised_2_percent\", \"semi\", \"semi_sup_first\", \"semi_mixed\", \"unsupervised\"])\n","\n","    if ground_config['loss_function'] != 'CCE':\n","        # 1\n","        activation_list = [defaults['activation_types'], ['relu'], ['relu'] * 5,\n","                           [keras.backend.sin, keras.backend.cos, keras.activations.linear],\n","                           [keras.backend.sin, keras.backend.cos, keras.activations.linear, 'relu', 'sigmoid']]\n","        gen_experiment(config_string, ground_config, 'activation_types', activation_list)\n","\n","        # 2\n","        gen_experiment(config_string, ground_config, 'input_layer_type',\n","                       ['dense', 'gaussian_noise', 'gaussian_dropout', 'sqrt_softmax', 'gaussian_kernel', 'CNN', 'VAE'])\n","\n","        # 3\n","        gen_experiment(config_string, ground_config, 'encoding_dim', [2, 3, 6])\n","\n","        # 4\n","        gen_experiment(config_string, ground_config, 'hidden_layers', [3, 5, 7, 9, 27])\n","\n","        # 5\n","        regularizer_list = [None, keras.regularizers.l2(0.01), activity_regularizer_default,\n","                            keras.regularizers.l1(0.01), keras.regularizers.l1(10 ** -4)]\n","        regularizer_strings = [\"none\", \"L2: 0.01\", \"L2: 10^-4\", \"L1: 0.01\", \"L1: 10^-4\"]\n","        for i in range(len(regularizer_list)):\n","            try:\n","                regularizer_list[i].__name__ = regularizer_strings[i]\n","            except:\n","                pass\n","        gen_experiment(config_string, ground_config, 'activity_regularizer', regularizer_list)\n","\n","        sigma_list = [0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n","        gen_experiment(config_string, ground_config, 'sigma', sigma_list)\n","\n","        # 7\n","        if ground_config['sampling_density'] == 100:\n","            gen_experiment(config_string, ground_config, 'BN_size', [2, 3, 4, 5])\n","        else:\n","            gen_experiment(config_string, ground_config, 'BN_size', [2, 3, 4, 5, 10, 20, 30])\n","\n","    # 8\n","    if ground_config['training_method'] != 'unsupervised':\n","        gen_experiment(config_string, ground_config, 'labeled_data_percentage',\n","                       [99, 50, 20, 10, 5, 2, 1, 0.5, 0.25, 0.125, 0.05, 0.01])\n","    # 9\n","    if ground_config['sampling_density'] != 100:\n","        gen_experiment(config_string, ground_config, 'sampling_density', [4, 15, 25, 50, 100, 150, 300])\n","\n","    if ground_config['loss_function'] != 'CCE':\n","        # 10-13\n","        gaussian_noise_sigma_strings = [\"lambda SD: 0.01\", \"lambda SD: 0.02\", \"lambda SD: 0.05\", \"lambda SD: 0.1\",\n","                                        \"lambda SD: 0.2\", \"lambda SD: (0.01/SD)*100\", \"lambda SD: (0.02/SD)*100\",\n","                                        \"lambda SD: (0.05/SD)*100\", \"lambda SD: (0.1/SD)*100\",\n","                                        \"lambda SD: (0.2/SD)*100\"]\n","        gaussian_noise_sigma_list = [lambda SD: 0.01, lambda SD: 0.02, lambda SD: 0.05, lambda SD: 0.1, lambda SD: 0.2,\n","                                     lambda SD: (0.01 / SD) * 100, lambda SD: (0.02 / SD) * 100,\n","                                     lambda SD: (0.05 / SD) * 100, lambda SD: (0.1 / SD) * 100,\n","                                     lambda SD: (0.2 / SD) * 100]\n","        for i in range(len(gaussian_noise_sigma_list)):\n","            gaussian_noise_sigma_list[i].__name__ = gaussian_noise_sigma_strings[i]\n","        gen_experiment(config_string, ground_config, 'gaussian_noise_sigma', gaussian_noise_sigma_list)\n","\n","        gen_experiment(config_string, ground_config, 'missing_entry', [0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\n","        gen_experiment(config_string, ground_config, 'missing_entry_combined', [0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\n","        gen_experiment(config_string, ground_config, 'missing_entry_no_denoising', [0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\n","        #14\n","        gen_experiment(config_string, ground_config, 'rows', [10**2,10**3,10**4,10**5,10**6])\n","\n","\n","if LOAD_DATA:\n","    try:\n","        experiment_config_results = load_from_csv(\"experiment_config_results\" + gpu_string + \".csv\")\n","    except:\n","        print('could not load data')\n","\n","print(\"Experiments: \" + str(len(experiments)))\n","print(\"Experiment configs: \" + str(len(experiment_config_list)))\n","print(\"\\n\\n\\n----------DONE---------\\n\\n\\n\")\n","\n","for experiment in experiments:\n","    print(experiment['full_string'])\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# @dispatch.add_dispatch_support\n","def JSD(y_true, y_pred):\n","    #     y_pred = ops.convert_to_tensor_v2(y_pred)\n","    #     y_true = math_ops.cast(y_true, y_pred.dtype)\n","    #     y_true = keras.backend.clip(y_true, keras.backend.epsilon(), 1)\n","    #     y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1)\n","    y_pred = ops.convert_to_tensor_v2(y_pred)\n","    y_true = math_ops.cast(y_true, y_pred.dtype)\n","    y_true = keras.backend.clip(y_true, keras.backend.epsilon(), 1)\n","    y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1)\n","    means = 0.5 * (y_true + y_pred)\n","    divergence_tensor = 0.5 * keras.losses.kld(y_true, means) + 0.5 * keras.losses.kld(y_pred, means)\n","\n","    return divergence_tensor\n","\n","\n","def generate_samplespace(func, x_min, x_max, sampling_density):\n","    grid = np.linspace(x_min, x_max, sampling_density + 1)\n","    probs = np.diff(func.cdf(grid))\n","    return probs / np.sum(probs)  # ensuring it is normalized\n","\n","\n","def normalize_df(df):\n","    newdf = df.div(df.sum(axis=1), axis=0)\n","    SD = len(newdf.columns)\n","    return newdf.fillna(1 / SD)\n","\n","\n","def prob_distance(x, y):\n","    xt = x.T  # this is bad practice, but I cannot debug the statements below without doing this\n","    yt = y.T\n","    res = JSD(x, y)\n","    return res\n","\n","\n","def make_bn(BN_size, sampling_density):\n","    bn = gum.BayesNet(\"Quasi-Continuous\")\n","    a = bn.add(gum.LabelizedVariable(\"A\", \"A binary variable\", 2))\n","    bn.cpt(a)[:] = [0.4, 0.6]\n","\n","    if BN_size > 1:\n","        b = bn.add(gum.RangeVariable(\"B\", \"A range variable\", 0, sampling_density - 1))\n","        bn.addArc(a, b)\n","        first = generate_samplespace(scipy.stats.truncnorm(-10, 3), -10, 3, sampling_density)\n","        second = generate_samplespace(scipy.stats.truncnorm(-2, 6), -2, 6, sampling_density)\n","        bn.cpt(b)[{'A': 0}] = first\n","        bn.cpt(b)[{'A': 1}] = second\n","\n","    if BN_size > 2:\n","        c = bn.add(gum.RangeVariable(\"C\", \"Another quasi continuous variable\", 0, sampling_density - 1))\n","        bn.addArc(b, c)\n","        l = []\n","        for i in range(sampling_density):\n","            # the size and the parameter of gamma depends on the parent value\n","            k = (i * 30.0) / sampling_density\n","            l.append(generate_samplespace(scipy.stats.gamma(k + 1), 4, 5 + k, sampling_density))\n","        bn.cpt(c)[:] = l\n","\n","        for d in range(BN_size - 3):\n","            # new variable\n","            d = bn.add(gum.RangeVariable(\"D\" + str(d), \"Another quasi continuous variable\", 0, sampling_density - 1))\n","            l = []\n","            bn.addArc(c, d)\n","            for i in range(sampling_density):\n","                # the size and the parameter of gamma depends on the parent value\n","                k = (i * 30.0) / sampling_density\n","                l.append(generate_samplespace(scipy.stats.gamma(k + 1), 4, 5 + k, sampling_density))\n","            bn.cpt(d)[:] = l\n","\n","    return bn\n","\n","\n","def make_df(use_previous_df, bn, mu, sigma, use_gaussian_noise, use_missing_entry, missing_entry_prob,rows):\n","    if use_previous_df:\n","        original_database = pd.read_csv(\"good_db.csv\")\n","    else:\n","        gum.generateCSV(bn, \"databases/database_original\" + gpu_string + \".csv\", rows)\n","        original_database = pd.read_csv(\"databases/database_original\" + gpu_string + \".csv\")\n","    original_database = original_database.reindex(sorted(original_database.columns), axis=1)\n","    original_database.to_csv(\"databases/database_original\" + gpu_string + \".csv\")\n","\n","    size_dict = {}\n","    for column_name in original_database.columns:\n","        size_dict[column_name] = bn.variable(column_name).domainSize()\n","\n","    shape = [original_database.shape[0], sum(size_dict.values())]\n","\n","    df_cols_sorted = sorted(list(original_database.columns))\n","    sizes_sorted = [size_dict[x] for x in df_cols_sorted]\n","    sizes_sorted_with_leading_zero = [0] + sizes_sorted\n","\n","    data = np.ones(original_database.shape[0] * original_database.shape[1])\n","    row = list(range(original_database.shape[0])) * original_database.shape[1]\n","    col = []\n","    for i in range(original_database.values.T.shape[0]):\n","        for item in original_database.values.T[i]:\n","            col.append(item + sum(sizes_sorted_with_leading_zero[0:i + 1]))\n","    # print(col[20000])\n","\n","    input3 = scipy.sparse.coo_matrix((data, (row, col)), shape=tuple(shape)).todense()\n","\n","    first_id2 = df_cols_sorted[:]\n","    second_id2 = [list(range(x)) for x in sizes_sorted]\n","\n","    arrays3 = [np.repeat(first_id2, sizes_sorted), [item for sublist in second_id2 for item in sublist]]\n","    tuples2 = list(zip(*arrays3))\n","    index2 = pd.MultiIndex.from_tuples(tuples2, names=['Variable', 'Value'])\n","\n","    hard_evidence = pd.DataFrame(input3, columns=index2)\n","    hard_evidence.to_csv(\"databases/ground_truth\" + gpu_string + \".csv\")\n","\n","    df = hard_evidence + 0\n","\n","    if use_gaussian_noise:\n","        noise = np.random.normal(mu, sigma, hard_evidence.shape)\n","        df = df + noise\n","        df = df.clip(lower=0, upper=1)\n","    if use_missing_entry:\n","        # TODO FIX\n","        amount_of_variables = len(sizes_sorted)\n","        rows = len(df)\n","        total_entries = amount_of_variables * rows  # amount of probability distributions in the PDB\n","        missing_entry_nrs = np.random.choice(total_entries, size=round(total_entries * missing_entry_prob),\n","                                             replace=False)\n","        m = missing_entry_nrs[:]  # using an alias for shorter code\n","        col_index = 0\n","        for attribute_nr, size in enumerate(sizes_sorted):\n","            entries_this_col = m[(m >= rows * attribute_nr) & (m < rows * (attribute_nr + 1))]\n","            rows_this_col = entries_this_col - (rows * attribute_nr)\n","            df.iloc[rows_this_col, col_index:col_index + size] = 1\n","\n","            col_index += size\n","\n","    for col in df_cols_sorted:\n","        df[col] = normalize_df(df[col])\n","\n","    df.to_csv(\"databases/noisy_data\" + gpu_string + \".csv\")\n","\n","    return df, hard_evidence, sizes_sorted\n","\n","\n","class Sampling(keras.layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","\n","class VAE_model(keras.Model):\n","    def __init__(self, encoder, decoder, loss_func, **kwargs):\n","        super(VAE_model, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.loss_func = loss_func\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def call(self, data):\n","        z_mean, z_log_var, z = self.encoder(data)\n","        reconstruction = self.decoder(z)\n","        return reconstruction\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            x, y = data\n","            z_mean, z_log_var, z = self.encoder(x)\n","            reconstruction = self.decoder(z)\n","\n","            #             reconstruction_loss = self.loss_func(data, reconstruction)\n","\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            #             print(\"kl_loss before reduce mean\", kl_loss)\n","            #             print(\"kl_loss after reduce sum 1\", tf.reduce_sum(kl_loss, axis=1))\n","            #             print(\"kl_loss after reduce mean\", tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1)))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","\n","            reconstruction_loss = tf.reduce_mean(\n","                self.loss_func(y, reconstruction)\n","            )\n","\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }\n","\n","\n","def train_network(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted, loss_function,\n","                  training_method, activity_regularizer, input_layer_type, labeled_data_percentage, VAE, CNN,\n","                  kernel_landmarks, CNN_layers, CNN_filters, CNN_kernel_size, gaussian_noise_sigma):\n","    x_train, y_train, x_train_nolabel = None, None, None\n","\n","    if training_method == 'supervised':\n","        x_train, y_train = df, hard_evidence\n","    elif training_method == \"unsupervised\":\n","        x_train = df\n","    elif training_method == \"supervised_2_percent\":\n","        x_train, _, y_train, _ = sklearn.model_selection.train_test_split(df, hard_evidence, test_size=0.98)\n","    elif training_method == \"semi\" or training_method == \"semi_supervised\" or training_method == \"semisupervised\" or training_method == \"semi_sup_first\" or training_method == \"semi_mixed\":\n","        x_train, x_train_nolabel, y_train, _ = sklearn.model_selection.train_test_split(df, hard_evidence, test_size=(\n","                                                                                                                             100 - labeled_data_percentage) / 100)  # semi supervised\n","    else:\n","        raise Exception(\"Invalid training method\")\n","\n","    x_train = np.float32(x_train)\n","    if y_train is not None:\n","        y_train = np.float32(y_train)\n","    if x_train_nolabel is not None:\n","        x_train_nolabel = np.float32(x_train_nolabel)\n","\n","    # types = ['relu','relu','relu','relu','relu']\n","    input_dim = sum(sizes_sorted)\n","    # this is our input placeholder\n","    #     input_layer = keras.layers.Input(shape=(None,input_dim))\n","    input_layer = keras.layers.Input(shape=(input_dim,))\n","\n","    # \"encoded\" is the encoded representation of the input\n","    if input_layer_type == 'dense' and not CNN:\n","        x = keras.layers.Dense(input_dim, activation='relu', activity_regularizer=activity_regularizer)(input_layer)\n","    elif CNN:\n","        x = tf.expand_dims(input_layer, axis=2)\n","        x = keras.layers.Conv1D(input_shape=(0, input_dim), filters=CNN_filters, kernel_size=CNN_kernel_size,\n","                                activation='relu')(x)\n","        x = keras.layers.MaxPooling1D(pool_size=2)(x)\n","        x = keras.layers.Flatten()(x)\n","\n","    elif input_layer_type == 'gaussian_noise':\n","        x = keras.layers.GaussianNoise(gaussian_noise_sigma)(input_layer)\n","    elif input_layer_type == 'gaussian_dropout':\n","        x = keras.layers.GaussianDropout(0.01)(input_layer)\n","    elif input_layer_type == 'sqrt_softmax':\n","        x = keras.layers.Lambda(keras.backend.sqrt)(input_layer)\n","        x = keras.layers.Softmax()(x)\n","    elif input_layer_type == \"gaussian_kernel\":\n","\n","        x = gkernel.GaussianKernel3(kernel_landmarks, input_dim)(input_layer)\n","\n","    encode_ratio = 0.1\n","    middle = hidden_layers // 2\n","    for i in range(hidden_layers):\n","        if CNN and i < CNN_layers - 1:\n","\n","            x = tf.expand_dims(x, axis=2)\n","            x = keras.layers.Conv1D(filters=CNN_filters, kernel_size=CNN_kernel_size, activation='relu')(x)\n","            x = keras.layers.MaxPooling1D(pool_size=2)(x)\n","            x = keras.layers.Flatten()(x)\n","\n","        elif VAE and i == middle:\n","\n","            z_mean = keras.layers.Dense(encoding_dim, name=\"z_mean\")(x)\n","            z_log_var = keras.layers.Dense(encoding_dim, name=\"z_log_var\")(x)\n","            z = Sampling()([z_mean, z_log_var])\n","            latent_inputs = keras.layers.Input(shape=(encoding_dim,))\n","            x = tf.add(latent_inputs, 0)\n","\n","        else:\n","            ratio = 2 ** (math.log2(encode_ratio) + abs(i - middle))\n","            size = encoding_dim if i == middle else max((min(input_dim, int(ratio * input_dim))), encoding_dim)\n","            #         print(size)\n","            if len(activation_types) > 1:\n","                x = keras.layers.concatenate(\n","                    [keras.layers.Dense(size, activation=type, activity_regularizer=activity_regularizer)(x) for type in\n","                     activation_types], axis=1)\n","            else:\n","                x = keras.layers.Dense(size, activation=activation_types[0], activity_regularizer=activity_regularizer)(\n","                    x)\n","\n","    final_layer_list = [keras.layers.Dense(size, activation='softmax', activity_regularizer=activity_regularizer)(x) for\n","                        size in sizes_sorted]\n","\n","    decoded = keras.layers.concatenate(final_layer_list, axis=1)\n","\n","\n","    if VAE:\n","        encoder = keras.models.Model(input_layer, [z_mean, z_log_var, z], name=\"encoder\")\n","        decoder = keras.models.Model(latent_inputs, decoded, name=\"decoder\")\n","        autoencoder = VAE_model(encoder, decoder, loss_function)\n","        autoencoder.compile(optimizer='adam', metrics=['accuracy'])  # semi supervised\n","    else:\n","        autoencoder = keras.models.Model(input_layer, outputs=decoded)\n","        autoencoder.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])  # semi supervised\n","\n","    hist = keras.callbacks.History()\n","\n","    if training_method == 'supervised' or training_method == \"supervised_2_percent\":\n","        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","    elif training_method == \"semi\" or training_method == \"semi_supervised\" or training_method == \"semisupervised\":\n","        # SEMI SUPERVISED\n","        autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","    elif training_method == \"unsupervised\":\n","        # UNSUPERVISED\n","        autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","    elif training_method == \"semi_sup_first\":\n","        autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","        autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","                        verbose=verbosity)\n","    elif training_method == \"semi_mixed\":\n","        for i in range(epochs):\n","            autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=1, batch_size=32, shuffle=True, callbacks=[hist],\n","                            verbose=verbosity)\n","            autoencoder.fit(x_train, y_train, epochs=1, batch_size=32, shuffle=True, callbacks=[hist],\n","                            verbose=verbosity)\n","    else:\n","        raise Exception(\"Invalid training method\")\n","    return autoencoder\n","\n","\n","def measure_performance(df, hard_evidence, autoencoder, sizes_sorted,rows):\n","    test_data = df.head(rows)\n","\n","    verify_data = hard_evidence.iloc[test_data.index]\n","    results = pd.DataFrame(autoencoder.predict(test_data))\n","\n","    results.to_csv(\"databases/post_cleaning\" + gpu_string + \".csv\")\n","\n","    i = 0\n","    distances_before = []\n","    distances_after = []\n","    for size in sizes_sorted:\n","        dist_before = prob_distance(verify_data.iloc[:, i:i + size], test_data.iloc[:, i:i + size])\n","        dist_after = prob_distance(verify_data.iloc[:, i:i + size], results.iloc[:, i:i + size])\n","        distances_before.append(np.nansum(dist_before))\n","        distances_after.append(np.nansum(dist_after))\n","        i += size\n","\n","    avg_distance_before = np.nansum(distances_before)\n","    avg_distance_after = np.nansum(distances_after)\n","    noise_left = 100 * avg_distance_after / avg_distance_before\n","    return noise_left\n","\n","\n","def custom_loss(y_true, y_pred, sizes_sorted, loss_func):\n","    i = 0\n","    total_loss = 0\n","    if loss_func == 'JSD':\n","        loss_func = JSD\n","    elif loss_func == \"CCE\":\n","        loss_func = keras.losses.categorical_crossentropy\n","    else:\n","        loss_func = keras.losses.get(loss_func)\n","\n","    loss_list = []\n","\n","    for size in sizes_sorted:\n","        new_loss = loss_func(y_true[:, i:i + size], y_pred[:, i:i + size])\n","        loss_list.append(new_loss)\n","        i += size\n","    good_loss = tf.math.add_n(loss_list)\n","    return good_loss\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","----- LOWEST RESULTS: 0, HIGHEST: 0 ------\n","\n","\n","0\n","(0) CCE, SD=4    training_method    supervised;    28.049435425663887\n","(1) CCE, SD=4    training_method    supervised_2_percent;    7.689202943478037\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-7-9efca0f5be29>\", line 58, in <module>\n","    result = run_experiment(**experiment['config'])\n","  File \"<ipython-input-7-9efca0f5be29>\", line 26, in run_experiment\n","    autoencoder = train_network(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted,\n","  File \"<ipython-input-6-f05d788d539f>\", line 311, in train_network\n","    autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\n","    return method(self, *args, **kwargs)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\n","    tmp_logs = train_function(iterator)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 807, in _call\n","    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\n","    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1843, in _filtered_call\n","    return self._call_flat(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1923, in _call_flat\n","    return self._build_call_outputs(self._inference_function.call(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 545, in call\n","    outputs = execute.execute(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 708, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 754, in getmodule\n","    os.path.realpath(f)] = module.__name__\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\ntpath.py\", line 664, in realpath\n","    if _getfinalpathname(spath) == path:\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-7-9efca0f5be29>\", line 58, in <module>\n","    result = run_experiment(**experiment['config'])\n","  File \"<ipython-input-7-9efca0f5be29>\", line 26, in run_experiment\n","    autoencoder = train_network(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted,\n","  File \"<ipython-input-6-f05d788d539f>\", line 311, in train_network\n","    autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\n","    return method(self, *args, **kwargs)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\n","    tmp_logs = train_function(iterator)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 807, in _call\n","    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\n","    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1843, in _filtered_call\n","    return self._call_flat(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1923, in _call_flat\n","    return self._build_call_outputs(self._inference_function.call(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 545, in call\n","    outputs = execute.execute(\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3347, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2056, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"C:\\Users\\freek\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 708, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 751, in getmodule\n","    f = getabsfile(module)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 720, in getabsfile\n","    _filename = getsourcefile(object) or getfile(object)\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\inspect.py\", line 705, in getsourcefile\n","    if os.path.exists(filename):\n","  File \"C:\\Users\\freek\\miniconda3\\lib\\genericpath.py\", line 19, in exists\n","    os.stat(path)\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[1;32m<ipython-input-7-9efca0f5be29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\") \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'full_string'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\";    \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-7-9efca0f5be29>\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(epochs, use_previous_df, BN_size, sampling_density, mu, sigma, activation_types, hidden_layers, encoding_dim, loss_function, training_method, activity_regularizer, input_layer_type, labeled_data_percentage, VAE, CNN, kernel_landmarks, CNN_layers, CNN_filters, CNN_kernel_size, gaussian_noise_sigma, use_gaussian_noise, use_missing_entry, missing_entry_prob, rows)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     autoencoder = train_network(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted,\n\u001b[0m\u001b[0;32m     27\u001b[0m                                 \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_layer_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-6-f05d788d539f>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted, loss_function, training_method, activity_regularizer, input_layer_type, labeled_data_percentage, VAE, CNN, kernel_landmarks, CNN_layers, CNN_filters, CNN_kernel_size, gaussian_noise_sigma)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# SEMI SUPERVISED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         autoencoder.fit(x_train_nolabel, x_train_nolabel, epochs=epochs, batch_size=32, shuffle=True, callbacks=[hist],\n\u001b[0m\u001b[0;32m    312\u001b[0m                         verbose=verbosity)\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2053\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2054\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3346\u001b[0m                         \u001b[0masy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3347\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3348\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2057\u001b[0m                                             value, tb, tb_offset=tb_offset)\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2053\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2054\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[0;32m   3153\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'async'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3155\u001b[1;33m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[0;32m   3156\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0;32m   3157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3366\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3367\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2054\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2057\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[0;32m   1143\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[0;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["# -------------\n","def run_experiment(epochs=epochs_default, use_previous_df=False, BN_size=BN_size_default,\n","                   sampling_density=sampling_density_default, mu=mu_default, sigma=sigma_default,\n","                   activation_types=activation_types_default, hidden_layers=hidden_layers_default,\n","                   encoding_dim=encoding_dim_default, loss_function=loss_function_default,\n","                   training_method=training_method_default, activity_regularizer=activity_regularizer_default,\n","                   input_layer_type=input_layer_type_default, labeled_data_percentage=labeled_data_percentage_default,\n","                   VAE=VAE_default, CNN=CNN_default, kernel_landmarks=kernel_landmarks_default,\n","                   CNN_layers=CNN_layers_default, CNN_filters=CNN_filters_default,\n","                   CNN_kernel_size=CNN_kernel_size_default, gaussian_noise_sigma=gaussian_noise_sigma_default,\n","                   use_gaussian_noise=use_gaussian_noise_default, use_missing_entry=use_missing_entry_default,\n","                   missing_entry_prob=missing_entry_prob_default,rows=rows_default):\n","    if TEST_RUN_EPOCHS:\n","        epochs = TEST_RUN_EPOCH_NR\n","\n","    bn = make_bn(BN_size, sampling_density)\n","    sigma = (sigma / sampling_density) * 100\n","    gaussian_noise_sigma = gaussian_noise_sigma(sampling_density)\n","    df, hard_evidence, sizes_sorted = make_df(use_previous_df, bn, mu, sigma, use_gaussian_noise, use_missing_entry,\n","                                              missing_entry_prob,rows)\n","\n","    if loss_function != 'MSE':\n","        old_loss = loss_function[:]\n","        loss_function = lambda y_true, y_pred: custom_loss(y_true, y_pred, sizes_sorted, old_loss)\n","\n","    autoencoder = train_network(epochs, df, hard_evidence, activation_types, hidden_layers, encoding_dim, sizes_sorted,\n","                                loss_function, training_method, activity_regularizer, input_layer_type,\n","                                labeled_data_percentage, VAE, CNN, kernel_landmarks, CNN_layers, CNN_filters,\n","                                CNN_kernel_size, gaussian_noise_sigma)\n","    noise_left = measure_performance(df, hard_evidence, autoencoder, sizes_sorted,rows)\n","    result = 100 - noise_left\n","    del autoencoder\n","    gc.collect()\n","    keras.backend.clear_session()\n","    return result\n","\n","\n","runs = 0\n","lowest_results = 0\n","\n","while lowest_results < 10:\n","    lowest_results = min([len(x) for x in experiment_config_results])\n","    lowest_results_forcpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if\n","                                 (x['config']['sampling_density'] * x['config']['BN_size']) < 100])\n","    lowest_results_forgpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if\n","                                 (x['config']['sampling_density'] * x['config']['BN_size']) >= 100])\n","    highest_results = max([len(x) for x in experiment_config_results])\n","    print(\"\\n\\n----- LOWEST RESULTS: \" + str(lowest_results) + \", HIGHEST: \" + str(highest_results) + \" ------\\n\\n\")\n","    for i in (range(len(experiments))):\n","        experiment = experiments[i]\n","        x = experiment\n","        previous_runs = len(experiment_config_results[experiment['mapping']])\n","        if previous_runs == lowest_results:\n","            # if previous_runs==lowest_results_forcpu and (x['config']['sampling_density']*x['config']['BN_size'])<100:\n","            # if previous_runs==lowest_results_forgpu and (x['config']['sampling_density']*x['config']['BN_size'])>=100:\n","            if runs == 0:\n","                print(i)\n","            result = run_experiment(**experiment['config'])\n","            print(\"(\" + str(i) + \") \" + experiment['full_string'] + \";    \" + str(result))\n","            experiment_config_results[experiment['mapping']].append(result)\n","            #             experiment_configs_and_results[freeze(experiment['config'])].append(result)\n","            if runs % 10 == 0 and runs > 0:\n","                clear_output(wait=True)\n","            with open(\"experiments\" + gpu_string, \"wb\") as dill_file:\n","                dill.dump(experiments, dill_file)\n","            experiment_configs_csv = [[experiment_config_strings[i]] + experiment_config_results[i] for i in\n","                                      range(len(experiment_config_results))]\n","            with open(\"experiment_config_results\" + gpu_string + \".csv\", \"w\", newline=\"\") as f:\n","                writer = csv.writer(f)\n","                writer.writerows(experiment_configs_csv)\n","            runs += 1\n","    lowest_results = min([len(x) for x in experiment_config_results])\n","    lowest_results_forcpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if\n","                                 (x['config']['sampling_density'] * x['config']['BN_size']) < 100])\n","    lowest_results_forgpu = min([len(experiment_config_results[x['mapping']]) for x in experiments if\n","                                 (x['config']['sampling_density'] * x['config']['BN_size']) >= 100])\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit (conda)","metadata":{"interpreter":{"hash":"acaf3325e2b9610722d5876fb194b771aa7b4a569003e8df92eaafe48eb5ed50"}}}}}